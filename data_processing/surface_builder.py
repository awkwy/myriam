"""
Constructeur et analyseur de surfaces de volatilit√©
Auteur: Assistant Claude
Date: Mai 2025

Ce module transforme les donn√©es d'options collect√©es en surfaces de volatilit√©
exploitables pour le pricing et l'analyse de risque.

CONCEPTS FONDAMENTAUX:
1. Surface de volatilit√© = repr√©sentation 3D de œÉ(K, T)
2. Interpolation = estimer œÉ pour des (K,T) non observ√©s
3. Arbitrage-free = contraintes pour √©viter les opportunit√©s d'arbitrage
"""

import pandas as pd
import numpy as np
from scipy.interpolate import griddata, RBFInterpolator, interp2d
from scipy.optimize import minimize
from scipy.stats import norm
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
from datetime import datetime, timedelta
import warnings
import logging
from typing import Dict, List, Tuple, Optional
import json

warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)


class VolatilitySurfaceBuilder:
    """
    Construit et analyse des surfaces de volatilit√© √† partir de donn√©es d'options.
    
    POURQUOI DES SURFACES DE VOLATILIT√â?
    - Le mod√®le Black-Scholes assume œÉ constant (faux en pratique!)
    - En r√©alit√©, œÉ varie avec K (smile) et T (term structure)
    - La surface capture ces variations pour un pricing pr√©cis
    """
    
    def __init__(self):
        self.surfaces = {}  # Stockage des surfaces par date
        self.surface_metrics = {}  # M√©triques calcul√©es
        self.interpolation_methods = {
            'linear': self._interpolate_linear,
            'cubic': self._interpolate_cubic,
            'rbf': self._interpolate_rbf,
            'svi': self._interpolate_svi  # Stochastic Volatility Inspired
        }
        
    def build_surface_from_data(self, options_df: pd.DataFrame, 
                               surface_date: str,
                               method: str = 'rbf') -> Dict:
        """
        Construit une surface de volatilit√© pour une date donn√©e.
        
        Args:
            options_df: DataFrame avec les donn√©es d'options
            surface_date: Date de la surface (format YYYY-MM-DD)
            method: M√©thode d'interpolation
            
        Returns:
            Dict contenant la surface et les m√©triques
        """
        logging.info(f"üèóÔ∏è  Construction surface pour {surface_date} avec m√©thode {method}")
        
        # Filtrer les donn√©es pour cette date
        daily_data = options_df[options_df['dataDate'] == surface_date].copy()
        
        if len(daily_data) < 10:
            logging.warning(f"‚ö†Ô∏è  Pas assez de points ({len(daily_data)}) pour {surface_date}")
            return None
        
        # Extraire les coordonn√©es et valeurs
        strikes = daily_data['strike'].values
        ttms = daily_data['yearsToExpiration'].values
        vols = daily_data['impliedVolatility'].values
        spot = daily_data['spotPrice'].iloc[0]
        
        # Filtrer les valeurs aberrantes
        mask = self._filter_outliers(strikes, ttms, vols, spot)
        strikes_clean = strikes[mask]
        ttms_clean = ttms[mask]
        vols_clean = vols[mask]
        
        logging.info(f"üìä Points valides: {len(vols_clean)}/{len(vols)}")
        
        # Cr√©er la grille d'interpolation
        strike_grid, ttm_grid = self._create_interpolation_grid(
            strikes_clean, ttms_clean, spot
        )
        
        # Interpoler la surface
        if method in self.interpolation_methods:
            vol_surface = self.interpolation_methods[method](
                strikes_clean, ttms_clean, vols_clean, 
                strike_grid, ttm_grid
            )
        else:
            raise ValueError(f"M√©thode inconnue: {method}")
        
        # Calculer les m√©triques de la surface
        metrics = self._calculate_surface_metrics(
            daily_data, strikes_clean, ttms_clean, vols_clean, spot
        )
        
        # V√©rifier l'absence d'arbitrage
        arbitrage_free = self._check_arbitrage_conditions(
            strike_grid, ttm_grid, vol_surface, spot
        )
        
        # Cr√©er l'objet surface
        surface = {
            'date': surface_date,
            'spot_price': spot,
            'strike_grid': strike_grid,
            'ttm_grid': ttm_grid,
            'vol_surface': vol_surface,
            'raw_strikes': strikes_clean,
            'raw_ttms': ttms_clean,
            'raw_vols': vols_clean,
            'metrics': metrics,
            'arbitrage_free': arbitrage_free,
            'method': method,
            'n_points': len(vols_clean)
        }
        
        # Stocker la surface
        self.surfaces[surface_date] = surface
        self.surface_metrics[surface_date] = metrics
        
        return surface
    
    def _filter_outliers(self, strikes: np.ndarray, ttms: np.ndarray, 
                        vols: np.ndarray, spot: float) -> np.ndarray:
        """
        Filtre les points aberrants selon plusieurs crit√®res.
        
        CRIT√àRES:
        1. Volatilit√© r√©aliste (5% - 200%)
        2. Moneyness raisonnable (50% - 200%)
        3. TTM > 0
        4. Coh√©rence locale (pas de sauts brutaux)
        """
        # Crit√®res de base
        vol_mask = (vols >= 5) & (vols <= 200)
        moneyness = strikes / spot
        moneyness_mask = (moneyness >= 0.5) & (moneyness <= 2.0)
        ttm_mask = ttms > 0.01  # Au moins quelques jours
        
        # Combiner les masques
        mask = vol_mask & moneyness_mask & ttm_mask
        
        # Filtrage statistique suppl√©mentaire
        if mask.sum() > 10:
            # Enlever les outliers > 3 √©carts-types
            vol_mean = vols[mask].mean()
            vol_std = vols[mask].std()
            statistical_mask = np.abs(vols - vol_mean) <= 3 * vol_std
            mask = mask & statistical_mask
        
        return mask
    
    def _create_interpolation_grid(self, strikes: np.ndarray, ttms: np.ndarray,
                                  spot: float, n_strikes: int = 50, 
                                  n_ttms: int = 30) -> Tuple[np.ndarray, np.ndarray]:
        """
        Cr√©e une grille r√©guli√®re pour l'interpolation.
        
        DESIGN:
        - Plus dense pr√®s d'ATM (plus important pour le trading)
        - Couvre 70% - 130% de moneyness typiquement
        - TTM de 1 semaine √† 2 ans
        """
        # Grille en moneyness plut√¥t qu'en strikes absolus
        moneyness_min = max(0.7, (strikes / spot).min())
        moneyness_max = min(1.3, (strikes / spot).max())
        
        # Grille plus dense pr√®s d'ATM
        moneyness_grid = np.concatenate([
            np.linspace(moneyness_min, 0.95, n_strikes // 3),
            np.linspace(0.95, 1.05, n_strikes // 3),
            np.linspace(1.05, moneyness_max, n_strikes // 3)
        ])
        
        strike_grid = moneyness_grid * spot
        
        # Grille temporelle (plus dense court terme)
        ttm_min = max(7/365, ttms.min())  # Au moins 1 semaine
        ttm_max = min(2.0, ttms.max())    # Max 2 ans
        
        ttm_grid = np.concatenate([
            np.linspace(ttm_min, 0.25, n_ttms // 3),    # Court terme
            np.linspace(0.25, 1.0, n_ttms // 3),        # Moyen terme
            np.linspace(1.0, ttm_max, n_ttms // 3)      # Long terme
        ])
        
        # Cr√©er le meshgrid
        strike_mesh, ttm_mesh = np.meshgrid(strike_grid, ttm_grid)
        
        return strike_mesh, ttm_mesh
    
    def _interpolate_linear(self, strikes: np.ndarray, ttms: np.ndarray, 
                           vols: np.ndarray, strike_grid: np.ndarray, 
                           ttm_grid: np.ndarray) -> np.ndarray:
        """Interpolation lin√©aire - rapide mais peu smooth"""
        points = np.column_stack((strikes, ttms))
        return griddata(points, vols, (strike_grid, ttm_grid), method='linear')
    
    def _interpolate_cubic(self, strikes: np.ndarray, ttms: np.ndarray, 
                          vols: np.ndarray, strike_grid: np.ndarray, 
                          ttm_grid: np.ndarray) -> np.ndarray:
        """Interpolation cubique - bon compromis smooth/pr√©cision"""
        points = np.column_stack((strikes, ttms))
        return griddata(points, vols, (strike_grid, ttm_grid), method='cubic')
    
    def _interpolate_rbf(self, strikes: np.ndarray, ttms: np.ndarray, 
                        vols: np.ndarray, strike_grid: np.ndarray, 
                        ttm_grid: np.ndarray) -> np.ndarray:
        """
        Interpolation RBF (Radial Basis Function) - tr√®s smooth.
        
        AVANTAGES:
        - Surface tr√®s lisse
        - Extrapolation raisonnable
        - Bon pour la visualisation
        
        INCONV√âNIENTS:
        - Plus lent
        - Peut sur-lisser
        """
        points = np.column_stack((strikes, ttms))
        rbf = RBFInterpolator(points, vols, kernel='thin_plate_spline', epsilon=2)
        
        # Reshape pour l'interpolation
        grid_points = np.column_stack((strike_grid.ravel(), ttm_grid.ravel()))
        vol_surface = rbf(grid_points).reshape(strike_grid.shape)
        
        # S'assurer que les volatilit√©s restent positives
        vol_surface = np.maximum(vol_surface, 5.0)
        
        return vol_surface
    
    def _interpolate_svi(self, strikes: np.ndarray, ttms: np.ndarray, 
                        vols: np.ndarray, strike_grid: np.ndarray, 
                        ttm_grid: np.ndarray) -> np.ndarray:
        """
        Interpolation SVI (Stochastic Volatility Inspired).
        
        CONCEPT: Param√©trise le smile de volatilit√© avec 5 param√®tres
        garantissant l'absence d'arbitrage.
        
        Pour simplifier, on utilise RBF ici mais avec des contraintes.
        """
        # Version simplifi√©e - utiliser RBF avec post-processing
        vol_surface = self._interpolate_rbf(
            strikes, ttms, vols, strike_grid, ttm_grid
        )
        
        # Appliquer des contraintes pour √©viter l'arbitrage
        vol_surface = self._enforce_no_arbitrage_constraints(
            strike_grid, ttm_grid, vol_surface
        )
        
        return vol_surface
    
    def _enforce_no_arbitrage_constraints(self, strike_grid: np.ndarray, 
                                         ttm_grid: np.ndarray, 
                                         vol_surface: np.ndarray) -> np.ndarray:
        """
        Applique des contraintes pour √©viter l'arbitrage.
        
        CONDITIONS SANS ARBITRAGE:
        1. œÉ(K,T) > 0 (√©vident)
        2. ‚àÇœÉ/‚àÇT ‚â• 0 (la vol augmente g√©n√©ralement avec le temps)
        3. Convexit√© en K (butterfly spread positif)
        """
        # Contrainte 1: Volatilit√© positive
        vol_surface = np.maximum(vol_surface, 5.0)
        
        # Contrainte 2: Croissance en temps (approximative)
        for i in range(vol_surface.shape[0] - 1):
            for j in range(vol_surface.shape[1]):
                if vol_surface[i+1, j] < vol_surface[i, j]:
                    # Lisser la transition
                    vol_surface[i+1, j] = vol_surface[i, j] * 1.01
        
        # Contrainte 3: Limiter les pentes extr√™mes
        for i in range(vol_surface.shape[0]):
            # Diff√©rences finies pour d√©tecter les pentes extr√™mes
            if vol_surface.shape[1] > 2:
                diffs = np.diff(vol_surface[i, :])
                max_slope = 0.5  # Max 50% de changement entre points adjacents
                
                for j in range(len(diffs)):
                    if abs(diffs[j]) > max_slope * vol_surface[i, j]:
                        # Adoucir la pente
                        vol_surface[i, j+1] = vol_surface[i, j] * (1 + np.sign(diffs[j]) * max_slope)
        
        return vol_surface
    
    def _calculate_surface_metrics(self, daily_data: pd.DataFrame, 
                                  strikes: np.ndarray, ttms: np.ndarray, 
                                  vols: np.ndarray, spot: float) -> Dict:
        """
        Calcule des m√©triques importantes de la surface.
        
        M√âTRIQUES CL√âS:
        1. ATM volatility: Vol √† la monnaie (r√©f√©rence principale)
        2. Skew: Asym√©trie du smile (mesure de peur du march√©)
        3. Term structure: Pente temporelle (anticipations)
        4. Butterfly: Convexit√© du smile (co√ªt des tail risks)
        """
        moneyness = strikes / spot
        
        # 1. ATM Volatility (moneyness ‚âà 1)
        atm_mask = (moneyness >= 0.95) & (moneyness <= 1.05)
        atm_vol = vols[atm_mask].mean() if atm_mask.any() else vols.mean()
        
        # 2. 25-Delta Skew (diff√©rence entre 25Œî put et call)
        # Approximation: 90% et 110% moneyness
        put_mask = (moneyness >= 0.85) & (moneyness <= 0.95)
        call_mask = (moneyness >= 1.05) & (moneyness <= 1.15)
        
        put_vol = vols[put_mask].mean() if put_mask.any() else np.nan
        call_vol = vols[call_mask].mean() if call_mask.any() else np.nan
        skew_25d = put_vol - call_vol if not (np.isnan(put_vol) or np.isnan(call_vol)) else 0
        
        # 3. Term Structure (pente 3m vs 1y)
        short_mask = (ttms >= 0.2) & (ttms <= 0.3)  # ~3 mois
        long_mask = (ttms >= 0.9) & (ttms <= 1.1)   # ~1 an
        
        short_vol = vols[short_mask].mean() if short_mask.any() else np.nan
        long_vol = vols[long_mask].mean() if long_mask.any() else np.nan
        term_slope = long_vol - short_vol if not (np.isnan(short_vol) or np.isnan(long_vol)) else 0
        
        # 4. Butterfly (convexit√© √† 25Œî)
        # Butterfly = œÉ(K_ATM) - 0.5*(œÉ(K_25ŒîP) + œÉ(K_25ŒîC))
        butterfly = atm_vol - 0.5 * (put_vol + call_vol) if not (np.isnan(put_vol) or np.isnan(call_vol)) else 0
        
        # 5. Vol of Vol (stabilit√© de la surface)
        vol_of_vol = vols.std()
        
        # 6. Smile Curvature (2√®me d√©riv√©e au niveau ATM)
        atm_region = (moneyness >= 0.9) & (moneyness <= 1.1)
        if atm_region.sum() >= 3:
            # Fit polynomial pour estimer la courbure
            poly_coef = np.polyfit(moneyness[atm_region], vols[atm_region], 2)
            smile_curvature = 2 * poly_coef[0]  # Coefficient du terme quadratique
        else:
            smile_curvature = 0
        
        return {
            'spot_price': spot,
            'atm_vol': round(atm_vol, 2),
            'skew_25d': round(skew_25d, 2),
            'term_slope': round(term_slope, 2),
            'butterfly_25d': round(butterfly, 2),
            'vol_of_vol': round(vol_of_vol, 2),
            'smile_curvature': round(smile_curvature, 4),
            'min_vol': round(vols.min(), 2),
            'max_vol': round(vols.max(), 2),
            'vol_range': round(vols.max() - vols.min(), 2),
            'n_options': len(daily_data),
            'avg_moneyness_range': round(moneyness.max() - moneyness.min(), 2)
        }
    
    def _check_arbitrage_conditions(self, strike_grid: np.ndarray, 
                                   ttm_grid: np.ndarray, 
                                   vol_surface: np.ndarray, 
                                   spot: float) -> Dict[str, bool]:
        """
        V√©rifie les conditions d'absence d'arbitrage.
        
        TYPES D'ARBITRAGE √Ä √âVITER:
        1. Calendar spread: Prix d√©cro√Æt avec le temps
        2. Butterfly spread: Non-convexit√© locale
        3. Volatilit√©s n√©gatives
        """
        checks = {
            'positive_vols': True,
            'calendar_arbitrage_free': True,
            'butterfly_arbitrage_free': True,
            'reasonable_values': True
        }
        
        # 1. V√©rifier que toutes les vols sont positives
        if (vol_surface <= 0).any():
            checks['positive_vols'] = False
        
        # 2. V√©rifier l'arbitrage calendaire (simpliste)
        # Les options plus longues devraient g√©n√©ralement avoir une vol >= courtes
        for j in range(vol_surface.shape[1]):  # Pour chaque strike
            for i in range(vol_surface.shape[0] - 1):
                if vol_surface[i+1, j] < vol_surface[i, j] * 0.95:  # Tol√©rance 5%
                    checks['calendar_arbitrage_free'] = False
                    break
        
        # 3. V√©rifier la convexit√© locale (butterfly)
        # Pour chaque maturit√©, v√©rifier la convexit√© en strike
        for i in range(vol_surface.shape[0]):
            if vol_surface.shape[1] >= 3:
                # Approximation de la d√©riv√©e seconde
                d2_vol = np.diff(vol_surface[i, :], n=2)
                if (d2_vol < -0.1).any():  # Tol√©rance pour la concavit√©
                    checks['butterfly_arbitrage_free'] = False
                    break
        
        # 4. V√©rifier que les valeurs sont raisonnables
        if (vol_surface > 500).any() or (vol_surface < 1).any():
            checks['reasonable_values'] = False
        
        return checks
    
    def build_all_surfaces(self, options_df: pd.DataFrame, 
                          method: str = 'rbf',
                          start_date: Optional[str] = None,
                          end_date: Optional[str] = None) -> Dict:
        """
        Construit toutes les surfaces pour la p√©riode donn√©e.
        
        Args:
            options_df: DataFrame avec toutes les donn√©es
            method: M√©thode d'interpolation
            start_date: Date de d√©but (optionnel)
            end_date: Date de fin (optionnel)
            
        Returns:
            Dict avec toutes les surfaces construites
        """
        # Obtenir toutes les dates uniques
        all_dates = sorted(options_df['dataDate'].unique())
        
        # Filtrer par p√©riode si sp√©cifi√©
        if start_date:
            all_dates = [d for d in all_dates if d >= start_date]
        if end_date:
            all_dates = [d for d in all_dates if d <= end_date]
        
        logging.info(f"üèóÔ∏è  Construction de {len(all_dates)} surfaces...")
        
        successful = 0
        failed = []
        
        for date in all_dates:
            try:
                surface = self.build_surface_from_data(
                    options_df, date, method
                )
                if surface:
                    successful += 1
                else:
                    failed.append(date)
            except Exception as e:
                logging.error(f"‚ùå Erreur pour {date}: {e}")
                failed.append(date)
        
        logging.info(f"‚úÖ Surfaces construites: {successful}/{len(all_dates)}")
        if failed:
            logging.warning(f"‚ö†Ô∏è  √âchecs: {failed[:5]}...")
        
        return self.surfaces
    
    def get_implied_volatility(self, surface_date: str, strike: float, 
                              time_to_maturity: float) -> float:
        """
        Obtient la volatilit√© implicite pour un (K,T) donn√©.
        
        UTILISATION:
        - Pour pricer une option sp√©cifique
        - Pour calculer les Greeks avec la bonne volatilit√©
        
        Args:
            surface_date: Date de la surface
            strike: Strike de l'option
            time_to_maturity: Temps jusqu'√† maturit√© (ann√©es)
            
        Returns:
            Volatilit√© implicite interpol√©e
        """
        if surface_date not in self.surfaces:
            raise ValueError(f"Surface non disponible pour {surface_date}")
        
        surface = self.surfaces[surface_date]
        
        # Interpolation bilin√©aire sur la surface
        from scipy.interpolate import interp2d
        
        # Cr√©er l'interpolateur
        f = interp2d(
            surface['strike_grid'][0, :],  # Strikes uniques
            surface['ttm_grid'][:, 0],      # TTMs uniques
            surface['vol_surface'],
            kind='linear',
            bounds_error=False,
            fill_value=None
        )
        
        # Obtenir la volatilit√©
        vol = f(strike, time_to_maturity)[0]
        
        # V√©rifier la validit√©
        if np.isnan(vol) or vol <= 0:
            # Utiliser la vol ATM comme fallback
            vol = surface['metrics']['atm_vol']
        
        return float(vol)
    
    def analyze_surface_dynamics(self, start_date: str, end_date: str) -> pd.DataFrame:
        """
        Analyse l'√©volution temporelle des m√©triques de surface.
        
        INSIGHTS POSSIBLES:
        - Augmentation du skew = march√© plus nerveux
        - Aplatissement de la term structure = incertitude court terme
        - Hausse du butterfly = demande pour la protection tail risk
        """
        metrics_list = []
        
        for date, metrics in sorted(self.surface_metrics.items()):
            if start_date <= date <= end_date:
                metrics_record = {'date': date}
                metrics_record.update(metrics)
                metrics_list.append(metrics_record)
        
        df_metrics = pd.DataFrame(metrics_list)
        df_metrics['date'] = pd.to_datetime(df_metrics['date'])
        df_metrics.set_index('date', inplace=True)
        
        # Calculer des m√©triques additionnelles
        df_metrics['vol_regime'] = pd.cut(
            df_metrics['atm_vol'],
            bins=[0, 15, 25, 40, 100],
            labels=['Low', 'Normal', 'High', 'Extreme']
        )
        
        # Changements journaliers
        df_metrics['atm_vol_change'] = df_metrics['atm_vol'].diff()
        df_metrics['skew_change'] = df_metrics['skew_25d'].diff()
        
        # Moyennes mobiles
        df_metrics['atm_vol_ma5'] = df_metrics['atm_vol'].rolling(5).mean()
        df_metrics['skew_ma5'] = df_metrics['skew_25d'].rolling(5).mean()
        
        return df_metrics
    
    def export_surface_data(self, surface_date: str, 
                           output_format: str = 'json') -> str:
        """
        Exporte une surface pour utilisation externe.
        
        Args:
            surface_date: Date de la surface
            output_format: Format d'export ('json', 'csv', 'npz')
            
        Returns:
            Chemin du fichier export√©
        """
        if surface_date not in self.surfaces:
            raise ValueError(f"Surface non disponible pour {surface_date}")
        
        surface = self.surfaces[surface_date]
        output_file = f"surface_{surface_date.replace('-', '')}"
        
        if output_format == 'json':
            # Convertir les arrays numpy en listes
            export_data = {
                'date': surface['date'],
                'spot_price': surface['spot_price'],
                'metrics': surface['metrics'],
                'method': surface['method'],
                'arbitrage_free': surface['arbitrage_free'],
                'strike_grid': surface['strike_grid'].tolist(),
                'ttm_grid': surface['ttm_grid'].tolist(),
                'vol_surface': surface['vol_surface'].tolist()
            }
            
            output_file += '.json'
            with open(output_file, 'w') as f:
                json.dump(export_data, f, indent=2)
                
        elif output_format == 'csv':
            # Format tabulaire
            data_list = []
            for i in range(surface['vol_surface'].shape[0]):
                for j in range(surface['vol_surface'].shape[1]):
                    data_list.append({
                        'date': surface['date'],
                        'strike': surface['strike_grid'][i, j],
                        'ttm': surface['ttm_grid'][i, j],
                        'implied_vol': surface['vol_surface'][i, j],
                        'spot': surface['spot_price']
                    })
            
            df_export = pd.DataFrame(data_list)
            output_file += '.csv'
            df_export.to_csv(output_file, index=False)
            
        elif output_format == 'npz':
            # Format numpy compress√©
            output_file += '.npz'
            np.savez_compressed(
                output_file,
                strike_grid=surface['strike_grid'],
                ttm_grid=surface['ttm_grid'],
                vol_surface=surface['vol_surface'],
                spot_price=surface['spot_price'],
                metrics=surface['metrics']
            )
        
        logging.info(f"üíæ Surface export√©e: {output_file}")
        return output_file


def main():
    """
    D√©montre l'utilisation du constructeur de surfaces de volatilit√©.
    """
    print("="*70)
    print("üèóÔ∏è  CONSTRUCTEUR DE SURFACES DE VOLATILIT√â")
    print("="*70)
    
    # Charger les donn√©es (assumant qu'elles ont √©t√© collect√©es)
    try:
        df = pd.read_csv('data/AAPL/AAPL_options_historical_7d.csv')
        print(f"‚úÖ Donn√©es charg√©es: {len(df)} options")
    except:
        print("‚ùå Fichier de donn√©es non trouv√©. Ex√©cutez d'abord le collecteur.")
        return
    
    # Initialiser le constructeur
    builder = VolatilitySurfaceBuilder()
    
    # Construire une surface pour une date
    dates = df['dataDate'].unique()
    if len(dates) > 0:
        test_date = dates[0]
        print(f"\nüìä Construction de la surface pour {test_date}")
        
        # Tester diff√©rentes m√©thodes
        methods = ['linear', 'cubic', 'rbf']
        
        for method in methods:
            print(f"\nüîß M√©thode: {method}")
            surface = builder.build_surface_from_data(df, test_date, method)
            
            if surface:
                print(f"‚úÖ Surface construite avec {surface['n_points']} points")
                print(f"üìà M√©triques:")
                for key, value in surface['metrics'].items():
                    print(f"   - {key}: {value}")
                
                print(f"üîç V√©rifications arbitrage:")
                for check, passed in surface['arbitrage_free'].items():
                    status = "‚úÖ" if passed else "‚ùå"
                    print(f"   {status} {check}")
    
    # Construire toutes les surfaces
    print("\nüèóÔ∏è  Construction de toutes les surfaces...")
    all_surfaces = builder.build_all_surfaces(df, method='rbf')
    
    # Analyser la dynamique
    if len(all_surfaces) >= 2:
        print("\nüìä Analyse de la dynamique des surfaces")
        metrics_df = builder.analyze_surface_dynamics(
            min(dates), max(dates)
        )
        
        print("\nüìà Statistiques des m√©triques:")
        print(metrics_df[['atm_vol', 'skew_25d', 'term_slope', 'butterfly_25d']].describe())
        
        # Exporter une surface
        print("\nüíæ Export de surface...")
        export_file = builder.export_surface_data(test_date, 'json')
        print(f"‚úÖ Surface export√©e: {export_file}")
    
    print("\n‚úÖ Construction termin√©e!")
    print("Les surfaces sont pr√™tes pour le pricing et la visualisation.")


if __name__ == "__main__":
    main()
