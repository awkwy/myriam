"""
Scraper de Donn√©es d'Options et Prix Historiques pour AAPL
Ce script r√©cup√®re toutes les donn√©es n√©cessaires pour l'analyse ML des options
Auteur: Assistant Claude
Date: Mai 2025
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import os
import json
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# Pour l'API alternative si yfinance ne fonctionne pas
import requests
from bs4 import BeautifulSoup

# =====================================================
# CONFIGURATION
# =====================================================

class ScraperConfig:
    """Configuration centralis√©e pour le scraping"""
    TICKER = 'AAPL'
    
    # P√©riode pour les donn√©es historiques
    START_DATE = '2022-01-01'  # 2+ ans d'historique
    END_DATE = datetime.now().strftime('%Y-%m-%d')
    
    # Maturit√©s d'options √† r√©cup√©rer (en nombre)
    MAX_EXPIRIES = 60  # R√©cup√©rer jusqu'√† 20 dates d'expiration
    
    # Param√®tres de d√©lai pour √©viter le rate limiting
    DELAY_BETWEEN_REQUESTS = 0.5  # secondes
    
    # Dossier de sauvegarde
    OUTPUT_DIR = 'options_data'
    
    # Param√®tres pour le calcul du VIX-like
    VIX_WINDOW = 30  # jours

# Cr√©er le dossier de sortie
os.makedirs(ScraperConfig.OUTPUT_DIR, exist_ok=True)

# =====================================================
# 1. R√âCUP√âRATION DES DONN√âES HISTORIQUES DE PRIX
# =====================================================

def fetch_historical_prices(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    R√©cup√®re l'historique complet des prix pour calculer la volatilit√© r√©alis√©e
    
    Cette fonction r√©cup√®re:
    - Prix OHLCV (Open, High, Low, Close, Volume)
    - Dividendes et splits si disponibles
    - Calcule les rendements et volatilit√©s sur plusieurs fen√™tres
    """
    print(f"\nüìä R√©cup√©ration des donn√©es historiques pour {ticker}...")
    print(f"   P√©riode: {start_date} √† {end_date}")
    
    try:
        # Cr√©er l'objet ticker
        stock = yf.Ticker(ticker)
        
        # R√©cup√©rer l'historique des prix
        hist = stock.history(start=start_date, end=end_date)
        
        if hist.empty:
            raise ValueError("Aucune donn√©e historique trouv√©e")
        
        print(f"‚úÖ {len(hist)} jours de donn√©es r√©cup√©r√©s")
        
        # Ajouter des colonnes calcul√©es importantes
        hist['Returns'] = hist['Close'].pct_change()
        hist['Log_Returns'] = np.log(hist['Close'] / hist['Close'].shift(1))
        
        # Calculer la volatilit√© r√©alis√©e sur plusieurs fen√™tres
        windows = [10, 20, 30, 60, 90, 252]  # Diff√©rentes fen√™tres en jours
        for window in windows:
            # Volatilit√© annualis√©e en pourcentage
            hist[f'Realized_Vol_{window}D'] = (
                hist['Log_Returns'].rolling(window=window).std() * np.sqrt(252) * 100
            )
            
            # Volatilit√© Parkinson (utilise High et Low pour plus de pr√©cision)
            hist[f'Parkinson_Vol_{window}D'] = (
                np.sqrt(252 / (window * 4 * np.log(2))) * 
                (np.log(hist['High'] / hist['Low'])).rolling(window=window).sum() * 100
            )
        
        # Ajouter des indicateurs techniques utiles pour les options
        hist['SMA_20'] = hist['Close'].rolling(window=20).mean()
        hist['SMA_50'] = hist['Close'].rolling(window=50).mean()
        hist['RSI'] = calculate_rsi(hist['Close'])
        
        # Volume moyen (utile pour √©valuer la liquidit√©)
        hist['Avg_Volume_20D'] = hist['Volume'].rolling(window=20).mean()
        
        # Calcul du rang de volatilit√© (o√π se situe la vol actuelle vs historique)
        hist['Vol_Rank_252D'] = hist['Realized_Vol_20D'].rolling(window=252).rank(pct=True) * 100
        
        # Informations sur les dividendes
        try:
            dividends = stock.dividends
            if not dividends.empty:
                # Joindre les dividendes aux donn√©es
                hist = hist.join(dividends.to_frame('Dividend'), how='left')
                hist['Dividend'].fillna(0, inplace=True)
                hist['Dividend_Yield'] = hist['Dividend'] / hist['Close'] * 4  # Annualis√© (trimestre)
                print(f"‚úÖ {len(dividends)} dividendes trouv√©s")
        except:
            hist['Dividend'] = 0
            hist['Dividend_Yield'] = 0
            print("‚ö†Ô∏è  Pas de donn√©es de dividendes disponibles")
        
        # Sauvegarder
        filename = os.path.join(ScraperConfig.OUTPUT_DIR, f'{ticker}_price_history.csv')
        hist.to_csv(filename)
        print(f"üíæ Donn√©es sauvegard√©es dans: {filename}")
        
        return hist
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des prix: {str(e)}")
        return pd.DataFrame()

def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
    """
    Calcule le RSI (Relative Strength Index)
    Utile pour identifier les conditions de surachat/survente
    """
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

# =====================================================
# 2. R√âCUP√âRATION DES DONN√âES D'OPTIONS ACTUELLES
# =====================================================

def fetch_options_chain(ticker: str, save_all: bool = True) -> pd.DataFrame:
    """
    R√©cup√®re la cha√Æne d'options compl√®te avec toutes les dates d'expiration
    
    Cette fonction:
    - R√©cup√®re toutes les expirations disponibles
    - Collecte les donn√©es pour calls et puts
    - Calcule les Greeks approximatifs
    - Identifie les caract√©ristiques importantes (volume, OI, spreads)
    """
    print(f"\nüìà R√©cup√©ration de la cha√Æne d'options pour {ticker}...")
    
    try:
        stock = yf.Ticker(ticker)
        
        # Obtenir toutes les dates d'expiration disponibles
        expirations = stock.options
        print(f"‚úÖ {len(expirations)} dates d'expiration trouv√©es")
        
        # Limiter si n√©cessaire
        if len(expirations) > ScraperConfig.MAX_EXPIRIES:
            expirations = expirations[:ScraperConfig.MAX_EXPIRIES]
            print(f"   Limitation √† {ScraperConfig.MAX_EXPIRIES} premi√®res expirations")
        
        all_options = []
        
        # R√©cup√©rer le prix actuel du sous-jacent
        current_price = stock.info.get('regularMarketPrice', stock.info.get('currentPrice', 0))
        if current_price == 0:
            # Fallback: utiliser le dernier close
            hist = stock.history(period="1d")
            current_price = hist['Close'].iloc[-1] if not hist.empty else 150  # Valeur par d√©faut
        
        print(f"   Prix actuel: ${current_price:.2f}")
        
        # R√©cup√©rer les donn√©es pour chaque expiration
        for i, exp_date in enumerate(expirations):
            try:
                print(f"   üìÖ Traitement de l'expiration {i+1}/{len(expirations)}: {exp_date}")
                
                # R√©cup√©rer les options pour cette date
                opt = stock.option_chain(exp_date)
                
                # Traiter les CALLs
                calls = opt.calls.copy()
                calls['optionType'] = 'CALL'
                calls['expirationDate'] = exp_date
                
                # Traiter les PUTs
                puts = opt.puts.copy()
                puts['optionType'] = 'PUT'
                puts['expirationDate'] = exp_date
                
                # Combiner calls et puts
                options_df = pd.concat([calls, puts], ignore_index=True)
                
                # Ajouter le prix du sous-jacent
                options_df['underlyingPrice'] = current_price
                
                # Calculer le temps jusqu'√† maturit√©
                exp_datetime = pd.to_datetime(exp_date)
                today = pd.Timestamp.now()
                days_to_expiry = (exp_datetime - today).days
                options_df['daysToExpiration'] = days_to_expiry
                options_df['yearsToExpiration'] = days_to_expiry / 365.25
                
                # Calculer la moneyness
                options_df['moneyness'] = options_df['strike'] / current_price
                options_df['logMoneyness'] = np.log(options_df['moneyness'])
                
                # Identifier ITM/OTM
                options_df['inTheMoney'] = (
                    ((options_df['optionType'] == 'CALL') & (options_df['strike'] < current_price)) |
                    ((options_df['optionType'] == 'PUT') & (options_df['strike'] > current_price))
                )
                
                # Calculer les spreads bid-ask
                options_df['bidAskSpread'] = options_df['ask'] - options_df['bid']
                options_df['bidAskSpreadPct'] = (
                    options_df['bidAskSpread'] / options_df['lastPrice'].replace(0, np.nan) * 100
                )
                
                # Score de liquidit√© bas√© sur le volume et l'open interest
                options_df['liquidityScore'] = (
                    options_df['volume'] * 0.3 + options_df['openInterest'] * 0.7
                )
                
                # Ajouter √† la liste
                all_options.append(options_df)
                
                # Petit d√©lai pour √©viter de surcharger l'API
                time.sleep(ScraperConfig.DELAY_BETWEEN_REQUESTS)
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erreur pour l'expiration {exp_date}: {str(e)}")
                continue
        
        # Combiner toutes les options
        if all_options:
            full_chain = pd.concat(all_options, ignore_index=True)
            print(f"\n‚úÖ Total: {len(full_chain)} options r√©cup√©r√©es")
            
            # Nettoyer et standardiser les colonnes
            full_chain = clean_options_data(full_chain)
            
            # Calculer la volatilit√© implicite approximative si non fournie
            if 'impliedVolatility' not in full_chain.columns:
                print("   üìä Estimation de la volatilit√© implicite...")
                full_chain['impliedVolatility'] = estimate_implied_volatility(full_chain)
            
            # Convertir la volatilit√© en pourcentage
            full_chain['impliedVolatilityPct'] = full_chain['impliedVolatility'] * 100
            
            # Sauvegarder
            if save_all:
                filename = os.path.join(ScraperConfig.OUTPUT_DIR, f'{ticker}_options_chain_full.csv')
                full_chain.to_csv(filename, index=False)
                print(f"üíæ Cha√Æne d'options compl√®te sauvegard√©e: {filename}")
            
            return full_chain
        else:
            print("‚ùå Aucune option r√©cup√©r√©e")
            return pd.DataFrame()
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des options: {str(e)}")
        return pd.DataFrame()

def clean_options_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Nettoie et standardise les donn√©es d'options
    
    Cette fonction:
    - Renomme les colonnes pour la coh√©rence
    - Remplit les valeurs manquantes
    - Supprime les donn√©es aberrantes
    """
    # Mapping des noms de colonnes pour standardisation
    column_mapping = {
        'lastTradeDate': 'lastTradeDate',
        'strike': 'strike',
        'lastPrice': 'lastPrice',
        'bid': 'bid',
        'ask': 'ask',
        'change': 'change',
        'percentChange': 'percentChange',
        'volume': 'volume',
        'openInterest': 'openInterest',
        'impliedVolatility': 'impliedVolatility'
    }
    
    # Renommer si n√©cessaire
    df = df.rename(columns=column_mapping)
    
    # Remplir les valeurs manquantes
    df['volume'].fillna(0, inplace=True)
    df['openInterest'].fillna(0, inplace=True)
    df['bid'].fillna(0, inplace=True)
    df['ask'].fillna(df['lastPrice'], inplace=True)
    
    # Supprimer les options avec des strikes extr√™mes (> 3x ou < 0.3x le prix)
    df = df[
        (df['moneyness'] >= 0.3) & 
        (df['moneyness'] <= 3.0)
    ]
    
    # Supprimer les options avec des prix n√©gatifs ou nuls
    df = df[df['lastPrice'] > 0]
    
    return df

def estimate_implied_volatility(df: pd.DataFrame) -> pd.Series:
    """
    Estime la volatilit√© implicite bas√©e sur les caract√©ristiques de l'option
    
    Utilise une approche simplifi√©e bas√©e sur:
    - La moneyness
    - Le temps jusqu'√† maturit√©
    - Le type d'option (call/put)
    """
    # Volatilit√© de base (peut √™tre ajust√©e selon l'actif)
    base_vol = 0.25  # 25% pour AAPL
    
    # Ajustement pour la moneyness (smile effect)
    moneyness_adjustment = 0.1 * np.abs(df['logMoneyness']) ** 1.5
    
    # Ajustement pour la maturit√© (structure √† terme)
    maturity_adjustment = 0.05 * np.exp(-2 * df['yearsToExpiration'])
    
    # Ajustement pour le skew (puts g√©n√©ralement plus chers)
    skew_adjustment = np.where(
        (df['optionType'] == 'PUT') & (df['moneyness'] < 1),
        0.05,  # 5% de plus pour les puts OTM
        0
    )
    
    # Calcul final avec un peu de bruit al√©atoire
    estimated_vol = (
        base_vol + 
        moneyness_adjustment + 
        maturity_adjustment + 
        skew_adjustment +
        np.random.normal(0, 0.02, len(df))  # 2% de bruit
    )
    
    # Limiter entre 5% et 100%
    return np.clip(estimated_vol, 0.05, 1.0)

# =====================================================
# 3. CALCUL DES INDICATEURS DE MARCH√â (VIX-LIKE)
# =====================================================

def calculate_vix_proxy(options_df: pd.DataFrame, spot_price: float) -> float:
    """
    Calcule un proxy du VIX bas√© sur les options √† 30 jours
    
    Le VIX mesure la volatilit√© implicite moyenne des options S&P 500 √† 30 jours.
    Ici, nous cr√©ons un proxy similaire pour AAPL.
    """
    # Filtrer les options proches de 30 jours
    target_days = 30
    tolerance = 10  # +/- 10 jours
    
    near_term = options_df[
        (options_df['daysToExpiration'] >= target_days - tolerance) &
        (options_df['daysToExpiration'] <= target_days + tolerance)
    ].copy()
    
    if len(near_term) == 0:
        return 25.0  # Valeur par d√©faut
    
    # Filtrer les options pr√®s de l'ATM (moneyness entre 0.9 et 1.1)
    atm_options = near_term[
        (near_term['moneyness'] >= 0.9) &
        (near_term['moneyness'] <= 1.1)
    ]
    
    if len(atm_options) == 0:
        return 25.0
    
    # Calculer la volatilit√© moyenne pond√©r√©e par l'open interest
    weights = atm_options['openInterest'] / atm_options['openInterest'].sum()
    vix_proxy = (atm_options['impliedVolatilityPct'] * weights).sum()
    
    return vix_proxy

# =====================================================
# 4. ENRICHISSEMENT DES DONN√âES D'OPTIONS
# =====================================================

def enrich_options_data(options_df: pd.DataFrame, price_history_df: pd.DataFrame) -> pd.DataFrame:
    """
    Enrichit les donn√©es d'options avec des features suppl√©mentaires
    
    Ajoute:
    - Volatilit√© historique correspondante
    - Ratio volatilit√© implicite/r√©alis√©e
    - Indicateurs techniques du sous-jacent
    - Greeks approximatifs
    """
    print("\nüîß Enrichissement des donn√©es d'options...")
    
    # Obtenir les derni√®res valeurs de volatilit√© r√©alis√©e
    if not price_history_df.empty:
        latest_data = price_history_df.iloc[-1]
        
        # Ajouter la volatilit√© r√©alis√©e
        for window in [10, 20, 30, 60]:
            col_name = f'Realized_Vol_{window}D'
            if col_name in latest_data:
                options_df[col_name] = latest_data[col_name]
        
        # Ratio volatilit√© implicite/r√©alis√©e (pour identifier les opportunit√©s)
        if 'Realized_Vol_20D' in options_df.columns:
            options_df['IV_RV_Ratio'] = (
                options_df['impliedVolatilityPct'] / options_df['Realized_Vol_20D']
            )
        
        # Ajouter des indicateurs techniques
        options_df['RSI'] = latest_data.get('RSI', 50)
        options_df['Vol_Rank'] = latest_data.get('Vol_Rank_252D', 50)
    
    # Calculer les Greeks approximatifs
    print("   üìä Calcul des Greeks approximatifs...")
    
    # Utiliser le taux sans risque actuel (peut √™tre mis √† jour)
    risk_free_rate = 0.05  # 5%
    
    # Delta approximatif (simplifi√©)
    options_df['delta_approx'] = calculate_approximate_delta(
        options_df['underlyingPrice'],
        options_df['strike'],
        options_df['yearsToExpiration'],
        options_df['impliedVolatility'],
        options_df['optionType']
    )
    
    # Gamma approximatif
    options_df['gamma_approx'] = calculate_approximate_gamma(
        options_df['underlyingPrice'],
        options_df['strike'],
        options_df['yearsToExpiration'],
        options_df['impliedVolatility']
    )
    
    # Vega approximatif (sensibilit√© √† la volatilit√©)
    options_df['vega_approx'] = calculate_approximate_vega(
        options_df['underlyingPrice'],
        options_df['strike'],
        options_df['yearsToExpiration'],
        options_df['impliedVolatility']
    )
    
    # Theta approximatif (d√©croissance temporelle)
    options_df['theta_approx'] = calculate_approximate_theta(
        options_df['underlyingPrice'],
        options_df['strike'],
        options_df['yearsToExpiration'],
        options_df['impliedVolatility'],
        options_df['optionType'],
        risk_free_rate
    )
    
    # Calculer le VIX proxy pour AAPL
    vix_proxy = calculate_vix_proxy(options_df, options_df['underlyingPrice'].iloc[0])
    options_df['VIX_Proxy'] = vix_proxy
    print(f"   üìà VIX Proxy calcul√©: {vix_proxy:.2f}%")
    
    # Identifier les options avec des caract√©ristiques int√©ressantes
    options_df['high_volume'] = options_df['volume'] > options_df['volume'].quantile(0.9)
    options_df['high_oi'] = options_df['openInterest'] > options_df['openInterest'].quantile(0.9)
    options_df['tight_spread'] = options_df['bidAskSpreadPct'] < 5  # Spread < 5%
    
    # Score de qualit√© global
    options_df['quality_score'] = (
        options_df['high_volume'].astype(int) * 0.3 +
        options_df['high_oi'].astype(int) * 0.3 +
        options_df['tight_spread'].astype(int) * 0.4
    )
    
    print(f"‚úÖ Enrichissement termin√©: {len(options_df.columns)} colonnes totales")
    
    return options_df


# =====================================================
# 5. GREEKS APPROXIMATIFS ‚Äî FONCTIONS CORRIG√âES
# =====================================================

def calculate_approximate_delta(S, K, T, sigma, option_type):
    """
    Delta approximatif (vectoris√©).
    `option_type` doit contenir 'CALL' ou 'PUT'.
    """
    from scipy.stats import norm
    T     = np.maximum(T, 0.001)
    sigma = np.maximum(sigma, 0.01)
    d1    = (np.log(S / K) + 0.5 * sigma**2 * T) / (sigma * np.sqrt(T))
    return np.where(option_type == 'CALL', norm.cdf(d1), norm.cdf(d1) - 1)

def calculate_approximate_gamma(S, K, T, sigma):
    """Gamma approximatif (vectoris√©)."""
    from scipy.stats import norm
    T     = np.maximum(T, 0.001)
    sigma = np.maximum(sigma, 0.01)
    d1    = (np.log(S / K) + 0.5 * sigma**2 * T) / (sigma * np.sqrt(T))
    return norm.pdf(d1) / (S * sigma * np.sqrt(T))

def calculate_approximate_vega(S, K, T, sigma):
    """Vega approximatif (vectoris√©, pour 1 % de variation de vol)."""
    from scipy.stats import norm
    T     = np.maximum(T, 0.001)
    sigma = np.maximum(sigma, 0.01)
    d1    = (np.log(S / K) + 0.5 * sigma**2 * T) / (sigma * np.sqrt(T))
    return S * norm.pdf(d1) * np.sqrt(T) / 100

def calculate_approximate_theta(S, K, T, sigma, option_type, r):
    """
    Theta approximatif (vectoris√©) ‚Äî r√©sultat par jour.
    `option_type` doit contenir 'CALL' ou 'PUT'.
    """
    from scipy.stats import norm
    T     = np.maximum(T, 0.001)
    sigma = np.maximum(sigma, 0.01)

    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)

    call_theta = (-S * norm.pdf(d1) * sigma / (2 * np.sqrt(T))
                  - r * K * np.exp(-r * T) * norm.cdf(d2))
    put_theta  = (-S * norm.pdf(d1) * sigma / (2 * np.sqrt(T))
                  + r * K * np.exp(-r * T) * norm.cdf(-d2))

    return np.where(option_type == 'CALL', call_theta, put_theta) / 365

# =====================================================
# 6. FORMATAGE FINAL POUR LE MOD√àLE ML
# =====================================================


def prepare_ml_dataset(options_df: pd.DataFrame, price_history_df: pd.DataFrame) -> pd.DataFrame:
    """
    Pr√©pare le dataset final pour le mod√®le ML avec toutes les features n√©cessaires
    
    Cette fonction:
    - S√©lectionne et renomme les colonnes pour correspondre au mod√®le
    - Ajoute les features calcul√©es
    - Filtre les donn√©es de qualit√© insuffisante
    - Sauvegarde le dataset pr√™t pour l'entra√Ænement
    """
    print("\nüéØ Pr√©paration du dataset final pour le ML...")
    
    # Copier pour √©viter de modifier l'original
    ml_df = options_df.copy()
    
    # Renommer les colonnes pour correspondre au format attendu par le mod√®le
    column_mapping = {
        'strike': 'Strike',
        'underlyingPrice': 'Prix_Sous_Jacent',
        'lastPrice': 'Prix_Option',
        'impliedVolatilityPct': 'Volatilite_Implicite',
        'yearsToExpiration': 'Temps_Maturite_Annees',
        'daysToExpiration': 'Jours_Jusqu_Maturite',
        'optionType': 'Type_Option',
        'volume': 'Volume',
        'openInterest': 'Open_Interest',
        'moneyness': 'Moneyness',
        'logMoneyness': 'Log_Moneyness',
        'delta_approx': 'Delta',
        'gamma_approx': 'Gamma',
        'vega_approx': 'Vega',
        'theta_approx': 'Theta',
        'bidAskSpread': 'Bid_Ask_Spread',
        'bidAskSpreadPct': 'Bid_Ask_Spread_Pct',
        'liquidityScore': 'Liquidity_Score',
        'VIX_Proxy': 'VIX_Proxy'
    }
    
    ml_df.rename(columns=column_mapping, inplace=True)
    
    # Ajouter les colonnes manquantes avec des valeurs par d√©faut
    ml_df['Taux_Sans_Risque'] = 0.05  # 5%
    ml_df['Dividend_Yield'] = 0.015  # 1.5% pour AAPL
    
    # Calculer Rho approximatif
    ml_df['Rho'] = ml_df['Temps_Maturite_Annees'] * ml_df['Strike'] * 0.01  # Simplifi√©
    
    # Greeks de second ordre
    ml_df['Vanna'] = ml_df['Vega'] * ml_df['Delta'] * 0.1  # Approximation
    ml_df['Volga'] = ml_df['Vega'] * ml_df['Gamma'] * 0.1  # Approximation
    
    # Features suppl√©mentaires
    ml_df['Strike_Ratio'] = ml_df['Strike'] / ml_df['Prix_Sous_Jacent']
    ml_df['Sqrt_Time'] = np.sqrt(ml_df['Temps_Maturite_Annees'])
    ml_df['Vol_Time'] = ml_df['Volatilite_Implicite'] * ml_df['Sqrt_Time']
    
    # Encoder le type d'option
    ml_df['Is_Call'] = (ml_df['Type_Option'] == 'CALL').astype(int)
    
    # Features de liquidit√©
    ml_df['Log_Volume'] = np.log1p(ml_df['Volume'])
    ml_df['Log_Open_Interest'] = np.log1p(ml_df['Open_Interest'])
    
    # Identifier OTM/ITM
    ml_df['Is_OTM'] = (
        ((ml_df['Type_Option'] == 'CALL') & (ml_df['Strike'] > ml_df['Prix_Sous_Jacent'])) |
        ((ml_df['Type_Option'] == 'PUT') & (ml_df['Strike'] < ml_df['Prix_Sous_Jacent']))
    ).astype(int)
    
    ml_df['OTM_Distance'] = np.abs(ml_df['Log_Moneyness']) * ml_df['Is_OTM']
    
    # Interactions entre Greeks
    ml_df['Delta_Gamma_Product'] = ml_df['Delta'] * ml_df['Gamma']
    ml_df['Vega_Volga_Ratio'] = ml_df['Vega'] / (ml_df['Volga'] + 0.001)
    
    # Calculer le skew de volatilit√© si possible
    ml_df['Volatility_Skew'] = calculate_volatility_skew_for_ml(ml_df)
    
    # Ratio IV/VIX
    ml_df['Vol_VIX_Ratio'] = ml_df['Volatilite_Implicite'] / ml_df['VIX_Proxy']
    
    # Filtrer les donn√©es de mauvaise qualit√©
    print("   üßπ Filtrage des donn√©es...")
    initial_count = len(ml_df)
    
    # Crit√®res de filtrage
    ml_df = ml_df[
        (ml_df['Prix_Option'] > 0.01) &  # Prix minimum
        (ml_df['Volume'] > 0) &  # Au moins un peu de volume
        (ml_df['Bid_Ask_Spread_Pct'] < 50) &  # Spread raisonnable
        (ml_df['Moneyness'] >= 0.5) & (ml_df['Moneyness'] <= 2.0) &  # Strikes raisonnables
        (ml_df['Temps_Maturite_Annees'] > 0.01) &  # Au moins quelques jours
        (ml_df['Volatilite_Implicite'] > 5) & (ml_df['Volatilite_Implicite'] < 200)  # Vol raisonnable
    ]
    
    filtered_count = initial_count - len(ml_df)
    print(f"   ‚úÖ {filtered_count} lignes filtr√©es ({filtered_count/initial_count*100:.1f}%)")
    
    # Ajouter la date de scraping
    ml_df['Date_Scraping'] = datetime.now().strftime('%Y-%m-%d')
    
    # Trier par type d'option et maturit√©
    ml_df.sort_values(['Type_Option', 'Temps_Maturite_Annees', 'Strike'], inplace=True)
    
    # Sauvegarder le dataset final
    filename = os.path.join(ScraperConfig.OUTPUT_DIR, f'{ScraperConfig.TICKER}_options_data_ml_ready.csv')
    ml_df.to_csv(filename, index=False)
    print(f"\nüíæ Dataset ML sauvegard√©: {filename}")
    print(f"   Shape: {ml_df.shape}")
    
    # Cr√©er aussi une version filtr√©e pour le mod√®le (comme dans le code original)
    # Garder seulement les options les plus liquides pour l'entra√Ænement initial
    ml_df_filtered = ml_df[
        (ml_df['Volume'] >= ml_df['Volume'].quantile(0.25)) |
        (ml_df['Open_Interest'] >= ml_df['Open_Interest'].quantile(0.25))
    ]
    
    filename_filtered = os.path.join(ScraperConfig.OUTPUT_DIR, f'{ScraperConfig.TICKER}_options_data_filter.csv')
    ml_df_filtered.to_csv(filename_filtered, index=False)
    print(f"   Dataset filtr√© sauvegard√©: {filename_filtered} (Shape: {ml_df_filtered.shape})")
    
    return ml_df

def calculate_volatility_skew_for_ml(df: pd.DataFrame) -> pd.Series:
    """
    Calcule le skew de volatilit√© pour chaque ligne bas√© sur la maturit√©
    
    Le skew mesure la diff√©rence de volatilit√© entre puts OTM et calls OTM
    """
    skew_values = []
    
    for idx, row in df.iterrows():
        # Trouver des options similaires (m√™me maturit√©, diff√©rents strikes)
        same_maturity = df[
            (df['Temps_Maturite_Annees'] == row['Temps_Maturite_Annees']) &
            (df['Type_Option'] == row['Type_Option'])
        ]
        
        if len(same_maturity) < 5:  # Pas assez de donn√©es
            skew_values.append(0)
            continue
        
        # Calculer le skew local
        atm_strike = row['Prix_Sous_Jacent']
        otm_puts = same_maturity[
            (same_maturity['Type_Option'] == 'PUT') & 
            (same_maturity['Strike'] < atm_strike * 0.95)
        ]
        otm_calls = same_maturity[
            (same_maturity['Type_Option'] == 'CALL') & 
            (same_maturity['Strike'] > atm_strike * 1.05)
        ]
        
        if len(otm_puts) > 0 and len(otm_calls) > 0:
            put_vol = otm_puts['Volatilite_Implicite'].mean()
            call_vol = otm_calls['Volatilite_Implicite'].mean()
            skew = put_vol - call_vol
        else:
            skew = 0
        
        skew_values.append(skew)
    
    return pd.Series(skew_values, index=df.index)

# =====================================================
# 7. RAPPORT DE QUALIT√â DES DONN√âES
# =====================================================

def generate_data_quality_report(ml_df: pd.DataFrame, price_df: pd.DataFrame) -> Dict:
    """
    G√©n√®re un rapport d√©taill√© sur la qualit√© des donn√©es collect√©es
    
    Analyse:
    - Compl√©tude des donn√©es
    - Distribution des features
    - Qualit√© de la liquidit√©
    - Couverture des strikes et maturit√©s
    """
    print("\nüìä G√©n√©ration du rapport de qualit√© des donn√©es...")
    
    report = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'ticker': ScraperConfig.TICKER,
        'data_summary': {
            'total_options': len(ml_df),
            'unique_expirations': ml_df['Temps_Maturite_Annees'].nunique(),
            'unique_strikes': ml_df['Strike'].nunique(),
            'calls_count': len(ml_df[ml_df['Type_Option'] == 'CALL']),
            'puts_count': len(ml_df[ml_df['Type_Option'] == 'PUT']),
            'price_history_days': len(price_df) if not price_df.empty else 0
        },
        'liquidity_analysis': {
            'avg_volume': ml_df['Volume'].mean(),
            'avg_open_interest': ml_df['Open_Interest'].mean(),
            'pct_with_volume': (ml_df['Volume'] > 0).mean() * 100,
            'pct_tight_spread': (ml_df['Bid_Ask_Spread_Pct'] < 5).mean() * 100
        },
        'volatility_analysis': {
            'avg_implied_vol': ml_df['Volatilite_Implicite'].mean(),
            'vol_range': [ml_df['Volatilite_Implicite'].min(), ml_df['Volatilite_Implicite'].max()],
            'vix_proxy': ml_df['VIX_Proxy'].iloc[0] if 'VIX_Proxy' in ml_df.columns else None
        },
        'moneyness_distribution': {
            'deep_otm_puts': len(ml_df[ml_df['Moneyness'] < 0.9]),
            'otm_puts': len(ml_df[(ml_df['Moneyness'] >= 0.9) & (ml_df['Moneyness'] < 0.97)]),
            'atm': len(ml_df[(ml_df['Moneyness'] >= 0.97) & (ml_df['Moneyness'] <= 1.03)]),
            'otm_calls': len(ml_df[(ml_df['Moneyness'] > 1.03) & (ml_df['Moneyness'] <= 1.1)]),
            'deep_otm_calls': len(ml_df[ml_df['Moneyness'] > 1.1])
        },
        'maturity_distribution': {
            'short_term_pct': (ml_df['Temps_Maturite_Annees'] < 0.1).mean() * 100,
            'medium_term_pct': ((ml_df['Temps_Maturite_Annees'] >= 0.1) & 
                               (ml_df['Temps_Maturite_Annees'] < 0.5)).mean() * 100,
            'long_term_pct': (ml_df['Temps_Maturite_Annees'] >= 0.5).mean() * 100
        },
        'data_quality_scores': {
            'completeness': 1 - ml_df.isnull().sum().sum() / (len(ml_df) * len(ml_df.columns)),
            'liquidity_score': ml_df['Liquidity_Score'].mean() if 'Liquidity_Score' in ml_df.columns else 0,
            'greeks_availability': sum([col in ml_df.columns for col in ['Delta', 'Gamma', 'Vega', 'Theta']]) / 4
        }
    }
    
    # Sauvegarder le rapport
    filename = os.path.join(ScraperConfig.OUTPUT_DIR, 'data_quality_report.json')
    with open(filename, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"üíæ Rapport de qualit√© sauvegard√©: {filename}")
    
    # Afficher un r√©sum√©
    print("\nüìà R√©sum√© du rapport:")
    print(f"   - Options totales: {report['data_summary']['total_options']:,}")
    print(f"   - Expirations uniques: {report['data_summary']['unique_expirations']}")
    print(f"   - Volume moyen: {report['liquidity_analysis']['avg_volume']:.0f}")
    print(f"   - Volatilit√© implicite moyenne: {report['volatility_analysis']['avg_implied_vol']:.1f}%")
    print(f"   - Score de compl√©tude: {report['data_quality_scores']['completeness']:.2%}")
    
    return report

# =====================================================
# 8. FONCTION PRINCIPALE
# =====================================================

def main():
    """
    Fonction principale qui orchestre tout le processus de scraping
    """
    print("üöÄ D√©marrage du scraping des donn√©es d'options pour AAPL")
    print("=" * 60)
    
    start_time = time.time()
    
    try:
        # 1. R√©cup√©rer l'historique des prix
        price_history = fetch_historical_prices(
            ScraperConfig.TICKER,
            ScraperConfig.START_DATE,
            ScraperConfig.END_DATE
        )
        
        # 2. R√©cup√©rer la cha√Æne d'options actuelle
        options_chain = fetch_options_chain(ScraperConfig.TICKER)
        
        if options_chain.empty:
            print("‚ùå √âchec de la r√©cup√©ration des options. Arr√™t du processus.")
            return
        
        # 3. Enrichir les donn√©es d'options
        enriched_options = enrich_options_data(options_chain, price_history)
        
        # 4. Pr√©parer le dataset pour le ML
        ml_dataset = prepare_ml_dataset(enriched_options, price_history)
        
        # 5. G√©n√©rer le rapport de qualit√©
        quality_report = generate_data_quality_report(ml_dataset, price_history)
        
        # Calculer le temps total
        elapsed_time = time.time() - start_time
        print(f"\n‚úÖ Processus termin√© en {elapsed_time:.1f} secondes")
        
        # R√©sum√© final
        print("\nüìä R√©sum√© final:")
        print(f"   - Fichiers cr√©√©s dans: {ScraperConfig.OUTPUT_DIR}/")
        print(f"   - Prix historiques: {len(price_history)} jours")
        print(f"   - Options r√©cup√©r√©es: {len(options_chain)}")
        print(f"   - Dataset ML final: {len(ml_dataset)} lignes")
        
        print("\nüéØ Prochaines √©tapes:")
        print("   1. V√©rifier la qualit√© des donn√©es dans le rapport")
        print("   2. Lancer finance3_enhanced.py pour l'entra√Ænement des mod√®les")
        print("   3. Ajuster les hyperparam√®tres selon les r√©sultats")
        
        # Cr√©er un fichier de m√©tadonn√©es pour le suivi
        metadata = {
            'scraping_date': datetime.now().isoformat(),
            'ticker': ScraperConfig.TICKER,
            'elapsed_time_seconds': elapsed_time,
            'files_created': [
                f'{ScraperConfig.TICKER}_price_history.csv',
                f'{ScraperConfig.TICKER}_options_chain_full.csv',
                f'{ScraperConfig.TICKER}_options_data_ml_ready.csv',
                f'{ScraperConfig.TICKER}_options_data_filter.csv',
                'data_quality_report.json'
            ],
            'data_stats': quality_report['data_summary']
        }
        
        with open(os.path.join(ScraperConfig.OUTPUT_DIR, 'scraping_metadata.json'), 'w') as f:
            json.dump(metadata, f, indent=2)
        
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {str(e)}")
        import traceback
        traceback.print_exc()

# =====================================================
# 9. FONCTIONS UTILITAIRES SUPPL√âMENTAIRES
# =====================================================

def download_alternative_data(ticker: str) -> Optional[pd.DataFrame]:
    """
    M√©thode alternative pour r√©cup√©rer des donn√©es si yfinance √©choue
    
    Utilise des sources alternatives ou des API payantes si disponibles
    """
    print("\nüîÑ Tentative de r√©cup√©ration via sources alternatives...")
    
    # Ici, vous pourriez impl√©menter:
    # - Scraping direct de Yahoo Finance avec BeautifulSoup
    # - Utilisation d'APIs alternatives (Alpha Vantage, IEX Cloud, etc.)
    # - Lecture de fichiers locaux de sauvegarde
    
    # Pour l'instant, retourner None
    return None

def validate_data_integrity(df: pd.DataFrame) -> bool:
    """
    Valide l'int√©grit√© des donn√©es r√©cup√©r√©es
    
    V√©rifie:
    - Coh√©rence des prix (bid <= prix <= ask)
    - Valeurs positives pour les volumes
    - Greeks dans des plages raisonnables
    """
    checks = {
        'prices_positive': (df['Prix_Option'] > 0).all(),
        'volumes_non_negative': (df['Volume'] >= 0).all(),
        'delta_range': df['Delta'].between(-1, 1).all() if 'Delta' in df.columns else True,
        'gamma_positive': (df['Gamma'] >= 0).all() if 'Gamma' in df.columns else True,
        'vega_positive': (df['Vega'] >= 0).all() if 'Vega' in df.columns else True
    }
    
    all_valid = all(checks.values())
    
    if not all_valid:
        print("\n‚ö†Ô∏è  Probl√®mes d'int√©grit√© d√©tect√©s:")
        for check, passed in checks.items():
            if not passed:
                print(f"   - {check}: FAILED")
    
    return all_valid

# =====================================================
# POINT D'ENTR√âE
# =====================================================

if __name__ == "__main__":
    # V√©rifier les d√©pendances
    try:
        import yfinance
        import scipy
        print("‚úÖ Toutes les d√©pendances sont install√©es")
    except ImportError as e:
        print(f"‚ùå D√©pendance manquante: {e}")
        print("   Installer avec: pip install yfinance scipy beautifulsoup4 requests")
        exit(1)
    
    # Lancer le scraping
    main()
