"""
Collecteur Unifi√© de Donn√©es d'Options - Module Principal
========================================================

Ce module unifie la collecte de donn√©es depuis plusieurs sources (Yahoo Finance, Polygon.io)
et structure les donn√©es selon le format requis pour le pricing d'options et d'autocalls.

Format de sortie standardis√©:
- Date, Sous-jacent, Option, Prix, T(ann√©es), Strike, Vol%, Type
- Maturit√©s: 1 semaine (0.019 ans) √† 2 ans maximum
- P√©riode: 6 mois d'historique quotidien

Auteur: Framework Options & Autocalls
Date: Mai 2025
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import time
import logging
import os
from typing import Dict, List, Optional, Tuple
import json
from scipy.stats import norm
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
warnings.filterwarnings('ignore')

# Configuration du logging avec format p√©dagogique
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('data_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class UnifiedOptionsCollector:
    """
    Collecteur unifi√© qui combine plusieurs sources de donn√©es pour cr√©er
    un dataset complet et coh√©rent pour le pricing d'options.
    
    Points p√©dagogiques cl√©s:
    - Standardisation des donn√©es de sources multiples
    - Calcul uniforme des Greeks selon Black-Scholes
    - Filtrage intelligent par maturit√© et liquidit√©
    - Structure optimis√©e pour les surfaces de volatilit√©
    """
    
    def __init__(self, config_path: str = "config/collector_config.json"):
        """
        Initialise le collecteur avec configuration flexible.
        
        La configuration permet de:
        - Choisir les sources de donn√©es (Yahoo, Polygon, etc.)
        - D√©finir les param√®tres de filtrage (maturit√©s min/max)
        - Configurer les taux sans risque par devise
        - Ajuster les seuils de qualit√© des donn√©es
        """
        # Charger la configuration
        self.config = self._load_config(config_path)
        
        # Param√®tres de filtrage des maturit√©s (entre 1 semaine et 2 ans)
        self.min_days_to_expiry = self.config.get('min_days_to_expiry', 7)
        self.max_days_to_expiry = self.config.get('max_days_to_expiry', 730)
        
        # Taux sans risque par d√©faut (peut varier selon la devise)
        self.risk_free_rates = self.config.get('risk_free_rates', {
            'USD': 0.05,
            'EUR': 0.04,
            'GBP': 0.045
        })
        
        # Statistiques de collecte pour monitoring
        self.stats = {
            'total_options_collected': 0,
            'options_filtered_out': 0,
            'successful_days': 0,
            'failed_days': 0,
            'data_quality_score': 0.0
        }
        
        logger.info("üìä Collecteur unifi√© initialis√© avec configuration:")
        logger.info(f"   - Maturit√©s: {self.min_days_to_expiry} √† {self.max_days_to_expiry} jours")
        logger.info(f"   - Sources actives: {self.config.get('active_sources', ['yahoo'])}")
    
    def _load_config(self, config_path: str) -> Dict:
        """Charge la configuration depuis un fichier JSON ou utilise les d√©fauts."""
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è  Fichier de config non trouv√©: {config_path}")
            logger.warning("   Utilisation de la configuration par d√©faut")
            return {
                'active_sources': ['yahoo'],
                'min_days_to_expiry': 7,
                'max_days_to_expiry': 730,
                'risk_free_rates': {'USD': 0.05},
                'quality_thresholds': {
                    'min_volume': 10,
                    'min_open_interest': 100,
                    'max_bid_ask_spread_pct': 50
                }
            }
    
    def calculate_black_scholes_greeks(self, S: float, K: float, T: float, 
                                     r: float, sigma: float, option_type: str) -> Dict[str, float]:
        """
        Calcule tous les Greeks selon le mod√®le Black-Scholes.
        
        Formules p√©dagogiques:
        - d1 = (ln(S/K) + (r + œÉ¬≤/2)T) / (œÉ‚àöT)
        - d2 = d1 - œÉ‚àöT
        
        Greeks calcul√©s:
        - Delta (Œî): Sensibilit√© au prix du sous-jacent
        - Gamma (Œì): Taux de changement du delta
        - Theta (Œò): D√©croissance temporelle (en jours)
        - Vega (ŒΩ): Sensibilit√© √† la volatilit√©
        - Rho (œÅ): Sensibilit√© aux taux d'int√©r√™t
        
        Args:
            S: Prix du sous-jacent
            K: Prix d'exercice (strike)
            T: Temps jusqu'√† maturit√© (ann√©es)
            r: Taux sans risque
            sigma: Volatilit√© implicite
            option_type: 'CALL' ou 'PUT'
            
        Returns:
            Dict avec tous les Greeks calcul√©s
        """
        # Protection contre les valeurs invalides
        if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:
            return {
                'delta': 0.0, 'gamma': 0.0, 'theta': 0.0, 
                'vega': 0.0, 'rho': 0.0
            }
        
        # Calculs fondamentaux Black-Scholes
        sqrt_T = np.sqrt(T)
        d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrt_T)
        d2 = d1 - sigma * sqrt_T
        
        # Fonctions de distribution normale
        N_d1 = norm.cdf(d1)
        N_d2 = norm.cdf(d2)
        n_d1 = norm.pdf(d1)
        
        # Calcul des Greeks selon le type d'option
        if option_type.upper() == 'CALL':
            delta = N_d1
            theta_annual = (
                -(S * n_d1 * sigma) / (2 * sqrt_T) - 
                r * K * np.exp(-r * T) * N_d2
            )
            rho = K * T * np.exp(-r * T) * N_d2 / 100
        else:  # PUT
            delta = N_d1 - 1
            theta_annual = (
                -(S * n_d1 * sigma) / (2 * sqrt_T) + 
                r * K * np.exp(-r * T) * norm.cdf(-d2)
            )
            rho = -K * T * np.exp(-r * T) * norm.cdf(-d2) / 100
        
        # Greeks communs aux calls et puts
        gamma = n_d1 / (S * sigma * sqrt_T)
        vega = S * n_d1 * sqrt_T / 100  # Divis√© par 100 pour avoir vega en %
        theta_daily = theta_annual / 365.25  # Conversion en theta journalier
        
        return {
            'delta': round(delta, 4),
            'gamma': round(gamma, 6),
            'theta': round(theta_daily, 4),
            'vega': round(vega, 4),
            'rho': round(rho, 4)
        }
    
    def estimate_implied_volatility(self, S: float, K: float, T: float, 
                                  market_price: float, option_type: str, 
                                  r: float = 0.05) -> float:
        """
        Estime la volatilit√© implicite par m√©thode num√©rique (Newton-Raphson).
        
        Principe p√©dagogique:
        La volatilit√© implicite est LA volatilit√© qui, inject√©e dans Black-Scholes,
        donne exactement le prix de march√© observ√©. C'est l'anticipation du march√©
        sur la volatilit√© future du sous-jacent.
        
        M√©thode:
        1. Estimation initiale bas√©e sur la moneyness
        2. It√©rations Newton-Raphson jusqu'√† convergence
        3. Bornes de s√©curit√© pour √©viter les valeurs aberrantes
        """
        # Estimation initiale intelligente bas√©e sur la moneyness
        moneyness = S / K
        if 0.8 < moneyness < 1.2:  # Near ATM
            sigma_init = 0.20  # 20% pour les options ATM
        else:  # OTM ou deep ITM
            sigma_init = 0.30  # Plus de vol pour les options √©loign√©es
        
        # Si le prix de march√© est tr√®s bas, retourner une estimation
        if market_price < 0.01:
            return sigma_init
        
        # Newton-Raphson avec maximum 50 it√©rations
        sigma = sigma_init
        for i in range(50):
            # Prix th√©orique avec volatilit√© actuelle
            bs_price = self._black_scholes_price(S, K, T, r, sigma, option_type)
            
            # Vega pour la d√©riv√©e
            vega = S * norm.pdf(self._d1(S, K, T, r, sigma)) * np.sqrt(T)
            
            # √âviter division par z√©ro
            if abs(vega) < 1e-10:
                break
            
            # Mise √† jour Newton-Raphson
            price_diff = bs_price - market_price
            sigma_new = sigma - price_diff / vega
            
            # Bornes de s√©curit√©
            sigma_new = max(0.01, min(3.0, sigma_new))  # Entre 1% et 300%
            
            # Test de convergence
            if abs(sigma_new - sigma) < 1e-6:
                break
                
            sigma = sigma_new
        
        return round(sigma, 4)
    
    def _black_scholes_price(self, S: float, K: float, T: float, r: float, 
                           sigma: float, option_type: str) -> float:
        """Calcule le prix Black-Scholes pour l'estimation de volatilit√© implicite."""
        if T <= 0 or sigma <= 0:
            return 0.0
            
        d1 = self._d1(S, K, T, r, sigma)
        d2 = d1 - sigma * np.sqrt(T)
        
        if option_type.upper() == 'CALL':
            return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
        else:
            return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)
    
    def _d1(self, S: float, K: float, T: float, r: float, sigma: float) -> float:
        """Calcule d1 pour Black-Scholes."""
        return (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
    
    def collect_yahoo_options(self, ticker: str, date: datetime) -> pd.DataFrame:
        """
        Collecte les donn√©es d'options depuis Yahoo Finance pour une date donn√©e.
        
        Processus:
        1. R√©cup√©ration du prix du sous-jacent
        2. Collecte de toutes les maturit√©s disponibles
        3. Filtrage par crit√®res de liquidit√© et maturit√©
        4. Calcul des Greeks et m√©triques
        5. Formatage selon le standard unifi√©
        
        Returns:
            DataFrame avec colonnes standardis√©es
        """
        logger.info(f"üì• Collecte Yahoo Finance pour {ticker} le {date.strftime('%Y-%m-%d')}")
        
        try:
            # Initialiser l'objet ticker
            stock = yf.Ticker(ticker)
            
            # Obtenir le prix du sous-jacent
            hist = stock.history(start=date - timedelta(days=5), end=date + timedelta(days=1))
            if hist.empty or date.strftime('%Y-%m-%d') not in hist.index.strftime('%Y-%m-%d'):
                logger.warning(f"‚ö†Ô∏è  Pas de donn√©es de prix pour {date}")
                return pd.DataFrame()
            
            spot_price = hist.loc[hist.index.strftime('%Y-%m-%d') == date.strftime('%Y-%m-%d'), 'Close'].iloc[0]
            
            # Obtenir toutes les dates d'expiration
            expirations = stock.options
            
            all_options = []
            
            for expiry in expirations:
                # Calculer les jours jusqu'√† expiration
                exp_date = pd.to_datetime(expiry)
                days_to_expiry = (exp_date - date).days
                
                # Filtrer selon nos crit√®res de maturit√©
                if not (self.min_days_to_expiry <= days_to_expiry <= self.max_days_to_expiry):
                    continue
                
                # R√©cup√©rer la cha√Æne d'options
                opt_chain = stock.option_chain(expiry)
                
                # Traiter calls et puts
                for opt_type, opt_data in [('CALL', opt_chain.calls), ('PUT', opt_chain.puts)]:
                    for _, opt in opt_data.iterrows():
                        # Filtres de qualit√©
                        if opt['volume'] < self.config.get('quality_thresholds', {}).get('min_volume', 10):
                            continue
                        
                        # Calculer le prix (mid si disponible)
                        bid = opt.get('bid', 0)
                        ask = opt.get('ask', 0)
                        if bid > 0 and ask > 0:
                            option_price = (bid + ask) / 2
                        else:
                            option_price = opt.get('lastPrice', 0)
                        
                        if option_price <= 0:
                            continue
                        
                        # Calculer les m√©triques
                        years_to_expiry = days_to_expiry / 365.25
                        
                        # Volatilit√© implicite
                        impl_vol = opt.get('impliedVolatility', 0)
                        if impl_vol <= 0:
                            impl_vol = self.estimate_implied_volatility(
                                S=spot_price,
                                K=opt['strike'],
                                T=years_to_expiry,
                                market_price=option_price,
                                option_type=opt_type
                            )
                        
                        # Calculer les Greeks
                        greeks = self.calculate_black_scholes_greeks(
                            S=spot_price,
                            K=opt['strike'],
                            T=years_to_expiry,
                            r=self.risk_free_rates.get('USD', 0.05),
                            sigma=impl_vol,
                            option_type=opt_type
                        )
                        
                        # Cr√©er l'enregistrement standardis√©
                        option_record = {
                            'Date': date.strftime('%Y-%m-%d'),
                            'Sous_Jacent': spot_price,
                            'Ticker': ticker,
                            'Option': f"{int(opt['strike']/spot_price*100)}% {years_to_expiry:.2f}Y",
                            'Prix': round(option_price, 2),
                            'T_Annees': round(years_to_expiry, 4),
                            'Strike': opt['strike'],
                            'Vol_Pct': round(impl_vol * 100, 2),
                            'Type': opt_type,
                            'Moneyness': round(opt['strike'] / spot_price, 4),
                            'Delta': greeks['delta'],
                            'Gamma': greeks['gamma'],
                            'Theta': greeks['theta'],
                            'Vega': greeks['vega'],
                            'Rho': greeks['rho'],
                            'Volume': opt.get('volume', 0),
                            'Open_Interest': opt.get('openInterest', 0),
                            'Bid': bid,
                            'Ask': ask,
                            'Spread_Pct': round((ask - bid) / option_price * 100, 2) if option_price > 0 else 0
                        }
                        
                        all_options.append(option_record)
                        self.stats['total_options_collected'] += 1
            
            if all_options:
                logger.info(f"‚úÖ Collect√© {len(all_options)} options pour {ticker} le {date.strftime('%Y-%m-%d')}")
                self.stats['successful_days'] += 1
            else:
                logger.warning(f"‚ö†Ô∏è  Aucune option valide trouv√©e pour {date}")
                self.stats['failed_days'] += 1
            
            return pd.DataFrame(all_options)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur collecte Yahoo pour {ticker}: {e}")
            self.stats['failed_days'] += 1
            return pd.DataFrame()
    
    def collect_historical_data(self, tickers: List[str], start_date: datetime, 
                              end_date: datetime, parallel_workers: int = 3) -> pd.DataFrame:
        """
        Collecte les donn√©es historiques pour plusieurs tickers sur une p√©riode.
        
        Strat√©gie de collecte:
        1. G√©n√©ration des jours de trading (excluant weekends et jours f√©ri√©s)
        2. Parall√©lisation intelligente pour optimiser la performance
        3. Sauvegarde incr√©mentale pour r√©sistance aux erreurs
        4. Consolidation et validation finale
        
        Args:
            tickers: Liste des sous-jacents √† collecter
            start_date: Date de d√©but (incluse)
            end_date: Date de fin (incluse)  
            parallel_workers: Nombre de threads parall√®les
            
        Returns:
            DataFrame consolid√© avec toutes les donn√©es
        """
        logger.info("üöÄ D√©but de la collecte historique")
        logger.info(f"   - Tickers: {tickers}")
        logger.info(f"   - P√©riode: {start_date.strftime('%Y-%m-%d')} √† {end_date.strftime('%Y-%m-%d')}")
        
        # G√©n√©rer les jours de trading
        trading_days = pd.bdate_range(start=start_date, end=end_date)
        logger.info(f"   - Jours de trading: {len(trading_days)}")
        
        # Cr√©er le r√©pertoire de sauvegarde
        output_dir = f"data/options_historical_{datetime.now().strftime('%Y%m%d')}"
        os.makedirs(output_dir, exist_ok=True)
        
        all_data = []
        
        # Traiter chaque ticker
        for ticker in tickers:
            logger.info(f"\nüìä Traitement de {ticker}")
            ticker_data = []
            
            # Collecter par batches de jours
            with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
                # Soumettre les t√¢ches
                future_to_date = {}
                for date in trading_days:
                    future = executor.submit(self.collect_yahoo_options, ticker, date)
                    future_to_date[future] = date
                
                # R√©cup√©rer les r√©sultats
                for future in as_completed(future_to_date):
                    date = future_to_date[future]
                    try:
                        df_day = future.result(timeout=60)
                        if not df_day.empty:
                            ticker_data.append(df_day)
                            
                            # Sauvegarde incr√©mentale
                            if len(ticker_data) % 10 == 0:
                                temp_df = pd.concat(ticker_data, ignore_index=True)
                                temp_file = f"{output_dir}/{ticker}_temp_{len(ticker_data)}.csv"
                                temp_df.to_csv(temp_file, index=False)
                                logger.info(f"üíæ Sauvegarde temporaire: {temp_file}")
                    
                    except Exception as e:
                        logger.error(f"‚ùå Erreur pour {date}: {e}")
            
            # Consolider les donn√©es du ticker
            if ticker_data:
                ticker_df = pd.concat(ticker_data, ignore_index=True)
                ticker_df.sort_values(['Date', 'Type', 'Strike', 'T_Annees'], inplace=True)
                
                # Sauvegarder les donn√©es du ticker
                ticker_file = f"{output_dir}/{ticker}_options_complete.csv"
                ticker_df.to_csv(ticker_file, index=False)
                logger.info(f"‚úÖ Sauvegard√©: {ticker_file} ({len(ticker_df)} lignes)")
                
                all_data.append(ticker_df)
        
        # Consolider toutes les donn√©es
        if all_data:
            final_df = pd.concat(all_data, ignore_index=True)
            
            # Calculer les m√©triques de qualit√©
            self._calculate_data_quality_metrics(final_df)
            
            # Sauvegarder le fichier final
            final_file = f"{output_dir}/all_options_historical.csv"
            final_df.to_csv(final_file, index=False)
            
            logger.info(f"\nüéâ Collecte termin√©e!")
            logger.info(f"   - Fichier final: {final_file}")
            logger.info(f"   - Total options: {len(final_df)}")
            logger.info(f"   - P√©riode couverte: {final_df['Date'].min()} √† {final_df['Date'].max()}")
            self._print_statistics()
            
            return final_df
        else:
            logger.error("‚ùå Aucune donn√©e collect√©e")
            return pd.DataFrame()
    
    def _calculate_data_quality_metrics(self, df: pd.DataFrame):
        """
        Calcule des m√©triques de qualit√© pour √©valuer la fiabilit√© des donn√©es.
        
        M√©triques calcul√©es:
        - Compl√©tude des surfaces (couverture strike/maturit√©)
        - Coh√©rence des volatilit√©s implicites
        - Liquidit√© moyenne
        - Sym√©trie calls/puts
        """
        if df.empty:
            return
        
        logger.info("\nüìä M√©triques de qualit√© des donn√©es:")
        
        # Compl√©tude par date
        completeness = df.groupby('Date').size()
        logger.info(f"   - Options par jour (moyenne): {completeness.mean():.0f}")
        logger.info(f"   - Options par jour (min/max): {completeness.min()}/{completeness.max()}")
        
        # Distribution des maturit√©s
        maturity_dist = df.groupby(pd.cut(df['T_Annees'], 
                                         bins=[0, 0.083, 0.25, 0.5, 1.0, 2.0],
                                         labels=['<1M', '1-3M', '3-6M', '6M-1Y', '1-2Y'])).size()
        logger.info(f"   - Distribution maturit√©s:")
        for mat, count in maturity_dist.items():
            logger.info(f"     ‚Ä¢ {mat}: {count} ({count/len(df)*100:.1f}%)")
        
        # Qualit√© des volatilit√©s
        vol_stats = df['Vol_Pct'].describe()
        logger.info(f"   - Volatilit√© implicite:")
        logger.info(f"     ‚Ä¢ Moyenne: {vol_stats['mean']:.1f}%")
        logger.info(f"     ‚Ä¢ √âcart-type: {vol_stats['std']:.1f}%")
        logger.info(f"     ‚Ä¢ Min/Max: {vol_stats['min']:.1f}%/{vol_stats['max']:.1f}%")
        
        # Score de qualit√© global
        quality_score = self._compute_quality_score(df)
        self.stats['data_quality_score'] = quality_score
        logger.info(f"   - Score de qualit√© global: {quality_score:.2f}/10")
    
    def _compute_quality_score(self, df: pd.DataFrame) -> float:
        """Calcule un score de qualit√© global de 0 √† 10."""
        score = 10.0
        
        # P√©nalit√©s pour manque de donn√©es
        avg_options_per_day = df.groupby('Date').size().mean()
        if avg_options_per_day < 50:
            score -= 2.0
        elif avg_options_per_day < 100:
            score -= 1.0
        
        # P√©nalit√©s pour volatilit√©s aberrantes
        aberrant_vols = ((df['Vol_Pct'] < 5) | (df['Vol_Pct'] > 200)).sum()
        aberrant_pct = aberrant_vols / len(df) * 100
        if aberrant_pct > 5:
            score -= 2.0
        elif aberrant_pct > 2:
            score -= 1.0
        
        # Bonus pour bonne liquidit√©
        avg_volume = df['Volume'].mean()
        if avg_volume > 1000:
            score += 0.5
        
        return max(0, min(10, score))
    
    def _print_statistics(self):
        """Affiche les statistiques de collecte."""
        logger.info("\nüìà Statistiques de collecte:")
        logger.info(f"   - Options collect√©es: {self.stats['total_options_collected']}")
        logger.info(f"   - Options filtr√©es: {self.stats['options_filtered_out']}")
        logger.info(f"   - Jours r√©ussis: {self.stats['successful_days']}")
        logger.info(f"   - Jours √©chou√©s: {self.stats['failed_days']}")
        logger.info(f"   - Score qualit√© donn√©es: {self.stats['data_quality_score']:.2f}/10")
        
        if self.stats['successful_days'] > 0:
            success_rate = self.stats['successful_days'] / (self.stats['successful_days'] + self.stats['failed_days']) * 100
            logger.info(f"   - Taux de succ√®s: {success_rate:.1f}%")


def main():
    """
    Fonction principale d√©montrant l'utilisation du collecteur unifi√©.
    
    Exemple p√©dagogique complet avec:
    1. Configuration personnalis√©e
    2. Collecte multi-tickers
    3. Analyse de la qualit√©
    4. Export pour les autres modules
    """
    print("=" * 80)
    print("üöÄ COLLECTEUR UNIFI√â DE DONN√âES D'OPTIONS")
    print("=" * 80)
    print("\nCe module collecte et structure les donn√©es d'options pour:")
    print("- Construction de surfaces de volatilit√©")
    print("- Pricing d'options et d'autocalls")
    print("- Backtesting de strat√©gies")
    print("- Calibration de mod√®les ML")
    print("=" * 80)
    
    # Configuration
    tickers = ['AAPL', 'MSFT', 'GOOGL']  # Ajouter vos tickers
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)  # 6 mois d'historique
    
    # Cr√©er le collecteur
    collector = UnifiedOptionsCollector()
    
    # Exemple 1: Collecte pour une date unique
    print("\nüìä Exemple 1: Collecte pour une date unique")
    df_single = collector.collect_yahoo_options('AAPL', datetime.now())
    if not df_single.empty:
        print(f"‚úÖ Collect√© {len(df_single)} options pour AAPL aujourd'hui")
        print(f"   Aper√ßu des donn√©es:")
        print(df_single[['Option', 'Prix', 'Strike', 'Vol_Pct', 'Delta']].head())
    
    # Exemple 2: Collecte historique compl√®te
    print("\nüìä Exemple 2: Collecte historique sur 6 mois")
    df_historical = collector.collect_historical_data(
        tickers=tickers,
        start_date=start_date,
        end_date=end_date,
        parallel_workers=3
    )
    
    if not df_historical.empty:
        # Afficher un r√©sum√© d√©taill√©
        print("\nüìà R√âSUM√â DES DONN√âES COLLECT√âES")
        print("=" * 60)
        print(f"P√©riode: {df_historical['Date'].min()} √† {df_historical['Date'].max()}")
        print(f"Tickers: {df_historical['Ticker'].unique()}")
        print(f"Total options: {len(df_historical):,}")
        
        print("\nüìä Distribution par ticker:")
        for ticker in df_historical['Ticker'].unique():
            ticker_data = df_historical[df_historical['Ticker'] == ticker]
            print(f"   {ticker}: {len(ticker_data):,} options")
        
        print("\nüìä Exemple de surface de volatilit√© (AAPL, derni√®re date):")
        last_date = df_historical['Date'].max()
        aapl_surface = df_historical[
            (df_historical['Ticker'] == 'AAPL') & 
            (df_historical['Date'] == last_date)
        ]
        
        # Afficher une mini surface
        pivot = aapl_surface.pivot_table(
            values='Vol_Pct',
            index=pd.cut(aapl_surface['Moneyness'], bins=[0.8, 0.95, 1.05, 1.2]),
            columns=pd.cut(aapl_surface['T_Annees'], bins=[0, 0.25, 0.5, 1.0, 2.0]),
            aggfunc='mean'
        )
        print(pivot.round(1))
        
        # Sauvegarder pour les autres modules
        output_file = 'data/options_data_for_pricing.csv'
        df_historical.to_csv(output_file, index=False)
        print(f"\n‚úÖ Donn√©es sauvegard√©es: {output_file}")
        print("\nüéØ Prochaines √©tapes:")
        print("   1. Utiliser data_processing/ pour cr√©er les features")
        print("   2. Construire les surfaces avec volatility_surface/")
        print("   3. Calibrer les mod√®les avec ml_models/")
        print("   4. Pricer les produits avec simulation/")


if __name__ == "__main__":
    main()
