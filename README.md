# Projet : Analyse et Pr√©diction des Prix d'Options avec des Mod√®les Machine Learning

## üìå Vue d'ensemble

Ce projet d√©veloppe une approche innovante pour mod√©liser la surface de volatilit√© implicite et pr√©dire les prix d'options financi√®res sur les actions Apple (AAPL) en utilisant des techniques avanc√©es de Machine Learning. L'objectif est de d√©passer les limites des mod√®les traditionnels comme Black-Scholes en capturant les dynamiques non-lin√©aires complexes du march√© des options.

## üéØ Objectifs du Projet

1. **Mod√©lisation de la surface de volatilit√© implicite** : Cr√©er une repr√©sentation tridimensionnelle pr√©cise de la volatilit√© implicite en fonction du strike et de la maturit√©.

2. **Pr√©diction des prix d'options** : D√©velopper des mod√®les pr√©dictifs robustes capables d'estimer avec pr√©cision les prix des options calls et puts.

3. **Analyse comparative des mod√®les** : Identifier le mod√®le ML optimal en termes de pr√©cision, robustesse et efficacit√© computationnelle.

## üìä Donn√©es Utilis√©es et Leur Pertinence

### Variables Principales

#### 1. Prix du Sous-jacent (Spot Price - S)
**Pertinence** : Variable fondamentale car elle d√©termine la valeur intrins√®que de l'option. La relation entre le prix spot et le strike d√©finit si l'option est dans la monnaie (ITM), √† la monnaie (ATM) ou hors de la monnaie (OTM).

**Impact** : Les variations du prix spot affectent directement le delta de l'option et sa probabilit√© d'exercice.

#### 2. Prix d'Exercice (Strike - K)
**Pertinence** : D√©termine le niveau auquel l'option peut √™tre exerc√©e. Le ratio S/K (moneyness) est crucial pour comprendre le comportement de l'option.

**Impact** : Influence directement la valeur intrins√®que et la sensibilit√© de l'option aux mouvements du sous-jacent.

#### 3. Temps jusqu'√† Maturit√© (Time to Maturity - T)
**Pertinence** : La valeur temps repr√©sente une composante majeure du prix de l'option. Plus l'√©ch√©ance est lointaine, plus l'option a de chances de devenir profitable.

**Impact** : Affecte le theta (d√©croissance temporelle) et la probabilit√© que l'option finisse ITM.

#### 4. Volatilit√© Implicite (œÉ_implied)
**Pertinence** : Repr√©sente les anticipations du march√© concernant la volatilit√© future. C'est le param√®tre le plus sensible et le plus difficile √† estimer.

**Impact** : Une augmentation de 1% de la volatilit√© peut significativement augmenter le prix de l'option, particuli√®rement pour les options ATM.

#### 5. Taux Sans Risque (r)
**Pertinence** : Repr√©sente le co√ªt d'opportunit√© du capital et influence la valeur pr√©sente des flux futurs.

**Impact** : Affecte principalement le rho de l'option et devient plus significatif pour les options de longue maturit√©.

### Variables Potentiellement Manquantes et Leur Importance

#### 1. Dividendes (q)
**Importance critique** : Les dividendes r√©duisent le prix du sous-jacent √† la date ex-dividende, impactant significativement les prix des options, surtout pour les puts.

**Recommandation** : Int√©grer le rendement en dividendes attendu ou les dates/montants de dividendes discrets.

#### 2. Greeks de Second Ordre
- **Gamma** : Mesure la convexit√© du delta. Crucial pour comprendre les risques de couverture.
- **Vanna** : Sensibilit√© du delta √† la volatilit√©. Important pour les strat√©gies de volatilit√©.
- **Volga** : Sensibilit√© du vega √† la volatilit√©. Essentiel pour le risk management.

#### 3. Volatilit√© R√©alis√©e Historique
**Importance** : Permet de comparer la volatilit√© implicite avec la volatilit√© historique pour identifier les opportunit√©s d'arbitrage.

**Utilisation** : Calculer sur diff√©rentes fen√™tres (10, 20, 30, 60 jours) pour capturer diff√©rents r√©gimes de march√©.

#### 4. Volume et Open Interest
**Importance** : Indicateurs de liquidit√© essentiels pour √©valuer la qualit√© des prix et les co√ªts de transaction.

**Impact** : Les options peu liquides peuvent avoir des spreads bid-ask importants affectant la rentabilit√©.

#### 5. Skew de Volatilit√©
**Importance** : Capture l'asym√©trie du smile de volatilit√©, particuli√®rement prononc√©e pour les indices.

**Calcul** : Diff√©rence de volatilit√© implicite entre puts OTM et calls OTM de m√™me distance au strike ATM.

#### 6. Structure √† Terme de la Volatilit√©
**Importance** : Les volatilit√©s implicites varient selon les maturit√©s, cr√©ant une structure √† terme.

**Application** : Permet de mieux pr√©dire les prix d'options de diff√©rentes √©ch√©ances.

#### 7. Indicateurs de March√©
- **VIX** : Indice de volatilit√© du march√©, proxy pour le sentiment de risque global.
- **Corr√©lations inter-march√©s** : Relations avec d'autres actifs (indices, commodit√©s, devises).

## üåê Surface de Volatilit√© Implicite

La surface de volatilit√© est une repr√©sentation tridimensionnelle montrant comment la volatilit√© implicite varie en fonction du strike et de la maturit√©. Cette visualisation r√©v√®le plusieurs ph√©nom√®nes importants :

### Caract√©ristiques Observ√©es

1. **Smile de Volatilit√©** : Les options OTM (particuli√®rement les puts) pr√©sentent souvent des volatilit√©s implicites plus √©lev√©es, refl√©tant la demande de protection contre les baisses.

2. **Structure √† Terme** : La volatilit√© tend √† converger vers une moyenne √† long terme (mean reversion).

3. **Dynamiques Asym√©triques** : Les surfaces ne sont pas sym√©triques, avec des pentes diff√©rentes c√¥t√© put et call.

### D√©fis et Limites

- **Liquidit√© Variable** : Les zones avec peu de transactions cr√©ent des discontinuit√©s artificielles.
- **Extrapolation aux Extr√™mes** : La pr√©cision diminue pour les strikes tr√®s √©loign√©s ou les maturit√©s tr√®s courtes/longues.
- **Arbitrage de Calendrier** : Des incoh√©rences peuvent appara√Ætre entre diff√©rentes maturit√©s.

## ‚öôÔ∏è Mod√®les Machine Learning √âvalu√©s

### 1. R√©gression Lin√©aire & Ridge

**Concept** : Mod√®les de base utilisant des relations lin√©aires entre variables.

**Avantages** :
- Interpr√©tabilit√© directe des coefficients
- Rapidit√© d'entra√Ænement et de pr√©diction
- Ridge ajoute une r√©gularisation L2 r√©duisant le surapprentissage

**Limites** :
- Incapacit√© √† capturer les non-lin√©arit√©s inh√©rentes aux options
- Performance m√©diocre sur les relations complexes entre strike, maturit√© et volatilit√©

**Cas d'usage optimal** : Benchmark initial ou options tr√®s proches de l'ATM avec peu de temps jusqu'√† maturit√©.

### 2. Random Forest

**Concept** : Ensemble d'arbres de d√©cision votant pour la pr√©diction finale.

**Avantages** :
- Capture naturellement les interactions non-lin√©aires
- Robuste au bruit et aux outliers
- Fournit l'importance des variables
- Peu de risque de surapprentissage gr√¢ce au bagging

**Limites** :
- Peut √™tre lent sur de tr√®s grands datasets
- Difficult√© √† extrapoler au-del√† des valeurs d'entra√Ænement
- Consommation m√©moire importante

**Cas d'usage optimal** : Donn√©es avec beaucoup de bruit ou quand l'interpr√©tabilit√© des features est importante.

### 3. Gradient Boosting

**Concept** : Construction s√©quentielle d'arbres corrigeant les erreurs des pr√©c√©dents.

**Avantages** :
- Excellente pr√©cision pr√©dictive
- Gestion efficace des interactions complexes
- Ajustement fin possible via learning rate

**Limites** :
- Sensible au surapprentissage sans r√©gularisation appropri√©e
- Plus lent que XGBoost ou LightGBM
- N√©cessite un tuning minutieux des hyperparam√®tres

**Cas d'usage optimal** : Quand la pr√©cision est prioritaire et que le temps d'entra√Ænement n'est pas critique.

### 4. XGBoost (eXtreme Gradient Boosting) - ‚≠ê Meilleur Mod√®le

**Concept** : Version optimis√©e du gradient boosting avec r√©gularisation avanc√©e.

**Avantages** :
- Performance pr√©dictive exceptionnelle (R¬≤ proche de 1)
- R√©gularisation L1/L2 int√©gr√©e
- Gestion native des valeurs manquantes
- Parall√©lisation efficace
- Pruning d'arbres intelligent

**Optimisations cl√©s** :
```python
params = {
    'max_depth': 6-10,           # Profondeur optimale pour options
    'learning_rate': 0.05-0.1,   # Balance vitesse/pr√©cision
    'n_estimators': 500-1000,    # Nombre d'arbres
    'subsample': 0.8,            # √âchantillonnage pour robustesse
    'colsample_bytree': 0.8,     # Features par arbre
    'gamma': 0.1,                # R√©gularisation minimale par split
    'reg_alpha': 0.1,            # L1 regularization
    'reg_lambda': 1.0            # L2 regularization
}
```

**Limites** :
- Complexit√© computationnelle pour le tuning
- Risque de surapprentissage sur petits datasets
- Moins interpr√©table que les mod√®les lin√©aires

### 5. LightGBM

**Concept** : Gradient boosting optimis√© pour la vitesse et l'efficacit√© m√©moire.

**Avantages** :
- Extr√™mement rapide (10x plus que XGBoost sur grands datasets)
- Consommation m√©moire r√©duite
- Gestion efficace des features cat√©gorielles
- Excellent pour les donn√©es haute dimension

**Innovations techniques** :
- Gradient-based One-Side Sampling (GOSS)
- Exclusive Feature Bundling (EFB)
- Histogram-based algorithm

**Limites** :
- Plus sensible au bruit que Random Forest
- Peut surapprendre sur petits datasets
- N√©cessite des donn√©es bien pr√©par√©es

### 6. R√©seaux de Neurones (Multi-Layer Perceptron)

**Concept** : Mod√®les profonds capables d'approximer toute fonction continue.

**Architecture typique** :
```python
model = Sequential([
    Dense(128, activation='relu', input_dim=n_features),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')  # Prix de l'option
])
```

**Avantages** :
- Capacit√© th√©orique illimit√©e de mod√©lisation
- Excellent pour capturer des patterns tr√®s complexes
- Peut int√©grer diff√©rents types de donn√©es

**Limites** :
- N√©cessite beaucoup de donn√©es pour bien g√©n√©raliser
- Temps d'entra√Ænement long
- Difficile √† interpr√©ter (bo√Æte noire)
- Sensible √† l'initialisation et √† l'architecture

## üìà Analyse des Performances par Type d'Option

### Options CALL
Les mod√®les performent g√©n√©ralement mieux sur les calls pour plusieurs raisons :
- Patterns de volatilit√© plus stables
- Moins d'asym√©trie dans la distribution des rendements
- Demande plus pr√©visible bas√©e sur les anticipations de hausse

### Options PUT
Les puts pr√©sentent des d√©fis suppl√©mentaires :
- Skew de volatilit√© plus prononc√© (fear gauge)
- Demande spike durant les p√©riodes de stress
- N√©cessit√© de capturer les queues de distribution (tail risk)

**Recommandation** : Entra√Æner des mod√®les s√©par√©s pour calls et puts peut am√©liorer significativement les performances.

## üîÑ Strat√©gie de Validation et Robustesse

### Validation Crois√©e Temporelle
Pour les donn√©es financi√®res, une validation crois√©e standard n'est pas appropri√©e. Utilisez plut√¥t :

```python
# Walk-forward validation
for train_end in monthly_dates:
    train = data[data.date < train_end]
    test = data[(data.date >= train_end) & 
                (data.date < train_end + 1_month)]
    model.fit(train)
    evaluate(model, test)
```

### M√©triques d'√âvaluation
- **R¬≤ Score** : Variance expliqu√©e (cible : > 0.95)
- **MAPE** : Erreur en pourcentage (cible : < 5%)
- **MAE en $** : Erreur absolue moyenne en dollars
- **Quantile Loss** : Pour √©valuer les queues de distribution

## üí° Recommandations pour l'Am√©lioration

### 1. Enrichissement des Features
- Ajouter les Greeks calcul√©s num√©riquement
- Int√©grer des indicateurs techniques du sous-jacent
- Inclure des variables macro√©conomiques (taux, inflation)

### 2. Approches Avanc√©es
- **Mod√®les Ensemble** : Combiner XGBoost avec des r√©seaux de neurones
- **Transfer Learning** : Utiliser des mod√®les pr√©-entra√Æn√©s sur d'autres actifs
- **Mod√®les Stochastiques** : Int√©grer des processus de volatilit√© stochastique

### 3. Gestion du Risque
- Impl√©menter des contraintes d'absence d'arbitrage
- V√©rifier la coh√©rence des surfaces de volatilit√© g√©n√©r√©es
- Backtesting sur diff√©rents r√©gimes de march√©

## üìÇ Structure du Projet

```
project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Donn√©es brutes de march√©
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Features engineered
‚îÇ   ‚îî‚îÄ‚îÄ surfaces/         # Surfaces de volatilit√©
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ baseline/         # Mod√®les simples
‚îÇ   ‚îú‚îÄ‚îÄ ensemble/         # Mod√®les avanc√©s
‚îÇ   ‚îî‚îÄ‚îÄ saved/           # Mod√®les entra√Æn√©s
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ finance3.py      # Pipeline principal
‚îÇ   ‚îú‚îÄ‚îÄ pranav.py        # Collecte de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ features.py      # Engineering des features
‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py    # M√©triques et validation
‚îî‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ model_comparison_results.csv
    ‚îî‚îÄ‚îÄ visualizations/
```

## üñ•Ô∏è Installation et Ex√©cution

### Pr√©requis
```bash
# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### Installation des D√©pendances
```bash
pip install -r requirements.txt
```

### Configuration
```python
# config.py
TICKER = 'AAPL'
START_DATE = '2023-01-01'
END_DATE = '2024-12-31'
RISK_FREE_RATE = 0.05  # Taux T-Bill 3 mois
```

### Ex√©cution
```bash
# Collecter les donn√©es
python pranav.py

# Lancer l'analyse compl√®te
python finance3.py

# G√©n√©rer les visualisations
python visualize_results.py
```

## üìä R√©sultats Attendus

1. **Surfaces de volatilit√©** : Visualisations 3D interactives
2. **Comparaison des mod√®les** : Tableau d√©taill√© des performances
3. **Pr√©dictions** : Prix d'options avec intervalles de confiance
4. **Feature Importance** : Analyse de l'importance des variables

## üìñ Ressources et R√©f√©rences

### Livres Fondamentaux
- Hull, J. "Options, Futures, and Other Derivatives" - Bible des produits d√©riv√©s
- Wilmott, P. "Paul Wilmott on Quantitative Finance" - Approche math√©matique approfondie
- Gatheral, J. "The Volatility Surface" - Focus sur la mod√©lisation de volatilit√©

### Articles Acad√©miques
- Hutchinson et al. (1994) "A Nonparametric Approach to Pricing and Hedging Derivative Securities"
- Culkin & Das (2017) "Machine Learning in Finance: The Case of Deep Learning for Option Pricing"

### Documentation Technique
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

---

üìß **Contact** : Pour questions ou contributions, ouvrez une issue sur le repository.

üåü **Note** : Ce projet est √† but √©ducatif et de recherche. Les mod√®les ne constituent pas des conseils d'investissement.
